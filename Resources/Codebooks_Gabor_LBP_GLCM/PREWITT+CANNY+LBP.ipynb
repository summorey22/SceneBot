{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'itemfreq' from 'scipy.stats' (/home/sumit/miniconda3/envs/scdt/lib/python3.8/site-packages/scipy/stats/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature\u001b[39;00m \u001b[39mimport\u001b[39;00m local_binary_pattern\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m itemfreq\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m normalize\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'itemfreq' from 'scipy.stats' (/home/sumit/miniconda3/envs/scdt/lib/python3.8/site-packages/scipy/stats/__init__.py)"
     ]
    }
   ],
   "source": [
    "#importing modules\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage.feature import local_binary_pattern\n",
    "from scipy.stats import itemfreq\n",
    "from sklearn.preprocessing import normalize\n",
    "import csv\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lbp definiton for positve trainging images\n",
    "def lbp_positive(folder_name,radius, no_points ):\n",
    "    i=0\n",
    "    label=1\n",
    "    for filename in os.listdir(folder_name):\n",
    "        #path\n",
    "        path=os.path.join(folder_name,filename)\n",
    "        \n",
    "        #read the image\n",
    "        a=cv2.imread(path)\n",
    "        \n",
    "        #change the image from rgb to grayscale\n",
    "        a = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #apply gaussian filter\n",
    "        img_gaussian = cv2.GaussianBlur(a,(3,3),0)\n",
    "        \n",
    "        #define the kernel for prewitt edge detection operat\n",
    "        \n",
    "        #change the image from rgb to grayscale\n",
    "        a = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #apply gaussian filter\n",
    "        img_gaussian = cv2.GaussianBlur(a,(3,3),0)\n",
    "        \n",
    "        #define the kernel for prewitt edge detection operator\n",
    "        kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
    "        kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
    "        img_prewittx = cv2.filter2D(img_gaussian, -1, kernelx)\n",
    "        img_prewitty = cv2.filter2D(img_gaussian, -1, kernely)\n",
    "        prewitt = img_prewittx + img_prewitty\n",
    "        \n",
    "        #apply canny edge detection.\n",
    "        img_canny = cv2.Canny(a,100,200)\n",
    "        final_img = prewitt + img_canny\n",
    "        \n",
    "        #set radius for LBP\n",
    "        #radius = 3\n",
    "        \n",
    "        # Number of points to be considered as neighbourers \n",
    "        #no_points = 8 * radius\n",
    "        \n",
    "        # Uniform LBP is used\n",
    "        lbp = local_binary_pattern(final_img, no_points, radius, method='uniform')\n",
    "        \n",
    "        # Calculate the histogram\n",
    "        x = itemfreq(lbp.ravel())\n",
    "        \n",
    "        # Normalize the histogram\n",
    "        hist = x[:, 1]/sum(x[:, 1])\n",
    "        \n",
    "        hist.reshape(26,-1)\n",
    "        hist = np.append(hist, label)\n",
    "        #writing features to csv files\n",
    "        with open(r'finalcsv.csv', 'a',newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(hist)\n",
    "        i=i+1\n",
    "        if i==3000:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lbp definition for negative training images\n",
    "def lbp_negative(folder_name,radius, no_points ):\n",
    "    i=0\n",
    "    label=0\n",
    "    for filename in os.listdir(folder_name):\n",
    "        #path\n",
    "        path=os.path.join(folder_name,filename)\n",
    "        \n",
    "        #read the image\n",
    "        a=cv2.imread(path)\n",
    "        \n",
    "        #change the image from rgb to grayscale\n",
    "        a = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #apply gaussian filter\n",
    "        img_gaussian = cv2.GaussianBlur(a,(3,3),0)\n",
    "        \n",
    "        #define the kernel for prewitt edge detection operator\n",
    "        kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
    "        kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
    "        img_prewittx = cv2.filter2D(img_gaussian, -1, kernelx)\n",
    "        img_prewitty = cv2.filter2D(img_gaussian, -1, kernely)\n",
    "        prewitt = img_prewittx + img_prewitty\n",
    "        \n",
    "        #apply canny edge detection.\n",
    "        img_canny = cv2.Canny(a,100,200)\n",
    "        final_img = prewitt + img_canny\n",
    "        \n",
    "        #set radius for LBP\n",
    "        #radius = 3\n",
    "        \n",
    "        # Number of points to be considered as neighbourers \n",
    "        #no_points = 8 * radius\n",
    "        \n",
    "        # Uniform LBP is used\n",
    "        lbp = local_binary_pattern(final_img, no_points, radius, method='uniform')\n",
    "        \n",
    "        # Calculate the histogram\n",
    "        x = itemfreq(lbp.ravel())\n",
    "        \n",
    "        # Normalize the histogram\n",
    "        hist = x[:, 1]/sum(x[:, 1])\n",
    "        \n",
    "        hist.reshape(26,-1)\n",
    "        hist = np.append(hist, label)\n",
    "        #writing features to csv files\n",
    "        with open(r'finalcsv.csv', 'a',newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(hist)\n",
    "        i=i+1\n",
    "        if i==3000:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DedicatedSoftwares\\Anaconda3forme\\lib\\site-packages\\ipykernel_launcher.py:38: DeprecationWarning: `itemfreq` is deprecated!\n",
      "`itemfreq` is deprecated and will be removed in a future version. Use instead `np.unique(..., return_counts=True)`\n"
     ]
    }
   ],
   "source": [
    "#calling the lbp function for positive trainging images\n",
    "lbp_positive(r\"C:\\Users\\omkar\\OneDrive\\Desktop\\College work\\TY\\ML FINAL PROJECT\\Positiveforml\",3,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DedicatedSoftwares\\Anaconda3forme\\lib\\site-packages\\ipykernel_launcher.py:38: DeprecationWarning: `itemfreq` is deprecated!\n",
      "`itemfreq` is deprecated and will be removed in a future version. Use instead `np.unique(..., return_counts=True)`\n"
     ]
    }
   ],
   "source": [
    "#calling the lbp function for negative training images\n",
    "lbp_negative(r\"C:\\Users\\omkar\\OneDrive\\Desktop\\College work\\TY\\ML FINAL PROJECT\\Negativeforml\",3,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.079839</td>\n",
       "      <td>0.031633</td>\n",
       "      <td>0.036310</td>\n",
       "      <td>0.026257</td>\n",
       "      <td>0.016166</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>0.005123</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.312426</td>\n",
       "      <td>0.408896</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.069631</td>\n",
       "      <td>0.026936</td>\n",
       "      <td>0.036213</td>\n",
       "      <td>0.031574</td>\n",
       "      <td>0.020260</td>\n",
       "      <td>0.013876</td>\n",
       "      <td>0.009354</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.008558</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.006637</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.294300</td>\n",
       "      <td>0.372606</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.076695</td>\n",
       "      <td>0.031225</td>\n",
       "      <td>0.034951</td>\n",
       "      <td>0.027227</td>\n",
       "      <td>0.015040</td>\n",
       "      <td>0.009917</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.003881</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.321101</td>\n",
       "      <td>0.394555</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.070543</td>\n",
       "      <td>0.028062</td>\n",
       "      <td>0.035611</td>\n",
       "      <td>0.033030</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>0.012478</td>\n",
       "      <td>0.008791</td>\n",
       "      <td>0.007666</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.004522</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.323468</td>\n",
       "      <td>0.369132</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.068311</td>\n",
       "      <td>0.026335</td>\n",
       "      <td>0.034660</td>\n",
       "      <td>0.030973</td>\n",
       "      <td>0.021580</td>\n",
       "      <td>0.014089</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.008364</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>0.008694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.005473</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.006501</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.306992</td>\n",
       "      <td>0.370277</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5995</td>\n",
       "      <td>0.062392</td>\n",
       "      <td>0.019659</td>\n",
       "      <td>0.029110</td>\n",
       "      <td>0.035068</td>\n",
       "      <td>0.030468</td>\n",
       "      <td>0.021076</td>\n",
       "      <td>0.014438</td>\n",
       "      <td>0.013371</td>\n",
       "      <td>0.012847</td>\n",
       "      <td>0.015254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>0.009102</td>\n",
       "      <td>0.010053</td>\n",
       "      <td>0.008578</td>\n",
       "      <td>0.008597</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.253352</td>\n",
       "      <td>0.339479</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5996</td>\n",
       "      <td>0.069553</td>\n",
       "      <td>0.024142</td>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.036213</td>\n",
       "      <td>0.026742</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>0.010868</td>\n",
       "      <td>0.009296</td>\n",
       "      <td>0.009490</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007336</td>\n",
       "      <td>0.007433</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.004095</td>\n",
       "      <td>0.293699</td>\n",
       "      <td>0.345378</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5997</td>\n",
       "      <td>0.068330</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>0.032661</td>\n",
       "      <td>0.036775</td>\n",
       "      <td>0.029362</td>\n",
       "      <td>0.018902</td>\n",
       "      <td>0.012362</td>\n",
       "      <td>0.011139</td>\n",
       "      <td>0.010965</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.006792</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>0.005608</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.292495</td>\n",
       "      <td>0.329465</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5998</td>\n",
       "      <td>0.066836</td>\n",
       "      <td>0.021464</td>\n",
       "      <td>0.032681</td>\n",
       "      <td>0.035009</td>\n",
       "      <td>0.028702</td>\n",
       "      <td>0.019911</td>\n",
       "      <td>0.013196</td>\n",
       "      <td>0.013585</td>\n",
       "      <td>0.012517</td>\n",
       "      <td>0.012789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.009257</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.008539</td>\n",
       "      <td>0.006773</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.265249</td>\n",
       "      <td>0.345863</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5999</td>\n",
       "      <td>0.065730</td>\n",
       "      <td>0.022007</td>\n",
       "      <td>0.031070</td>\n",
       "      <td>0.033961</td>\n",
       "      <td>0.029090</td>\n",
       "      <td>0.019115</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>0.013196</td>\n",
       "      <td>0.012614</td>\n",
       "      <td>0.011877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009102</td>\n",
       "      <td>0.008869</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.289313</td>\n",
       "      <td>0.328223</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.079839  0.031633  0.036310  0.026257  0.016166  0.008209  0.005783   \n",
       "1     0.069631  0.026936  0.036213  0.031574  0.020260  0.013876  0.009354   \n",
       "2     0.076695  0.031225  0.034951  0.027227  0.015040  0.009917  0.007103   \n",
       "3     0.070543  0.028062  0.035611  0.033030  0.020008  0.012478  0.008791   \n",
       "4     0.068311  0.026335  0.034660  0.030973  0.021580  0.014089  0.009994   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5995  0.062392  0.019659  0.029110  0.035068  0.030468  0.021076  0.014438   \n",
       "5996  0.069553  0.024142  0.034447  0.036213  0.026742  0.016476  0.010868   \n",
       "5997  0.068330  0.022667  0.032661  0.036775  0.029362  0.018902  0.012362   \n",
       "5998  0.066836  0.021464  0.032681  0.035009  0.028702  0.019911  0.013196   \n",
       "5999  0.065730  0.022007  0.031070  0.033961  0.029090  0.019115  0.013119   \n",
       "\n",
       "            7         8         9   ...        17        18        19  \\\n",
       "0     0.005123  0.004561  0.005162  ...  0.002989  0.002368  0.003086   \n",
       "1     0.008325  0.008558  0.008403  ...  0.004852  0.004405  0.005861   \n",
       "2     0.006327  0.005958  0.005803  ...  0.003377  0.002969  0.003881   \n",
       "3     0.007666  0.006851  0.007180  ...  0.004211  0.004114  0.004522   \n",
       "4     0.008364  0.007452  0.008694  ...  0.005570  0.004056  0.005473   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5995  0.013371  0.012847  0.015254  ...  0.009140  0.009102  0.010053   \n",
       "5996  0.009296  0.009490  0.009587  ...  0.007336  0.007433  0.007258   \n",
       "5997  0.011139  0.010965  0.011605  ...  0.007258  0.006035  0.008772   \n",
       "5998  0.013585  0.012517  0.012789  ...  0.008714  0.007995  0.009257   \n",
       "5999  0.013196  0.012614  0.011877  ...  0.009102  0.008869  0.008830   \n",
       "\n",
       "            20        21        22        23        24        25   26  \n",
       "0     0.004328  0.005997  0.005356  0.003784  0.312426  0.408896  1.0  \n",
       "1     0.006637  0.008190  0.008015  0.005589  0.294300  0.372606  1.0  \n",
       "2     0.004269  0.005085  0.004871  0.003260  0.321101  0.394555  1.0  \n",
       "3     0.004813  0.006035  0.004871  0.003978  0.323468  0.369132  1.0  \n",
       "4     0.006307  0.006482  0.006501  0.004890  0.306992  0.370277  1.0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "5995  0.008578  0.008597  0.008811  0.005861  0.253352  0.339479  0.0  \n",
       "5996  0.007937  0.007374  0.005453  0.004095  0.293699  0.345378  0.0  \n",
       "5997  0.006792  0.007472  0.005608  0.003454  0.292495  0.329465  0.0  \n",
       "5998  0.008772  0.008539  0.006773  0.005589  0.265249  0.345863  0.0  \n",
       "5999  0.008015  0.007530  0.006074  0.003940  0.289313  0.328223  0.0  \n",
       "\n",
       "[6000 rows x 27 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the csv file into 'data' variable\n",
    "data= pd.read_csv('C:\\\\Users\\\\omkar\\\\OneDrive\\\\Desktop\\\\College work\\\\TY\\\\ML FINAL PROJECT\\\\finalcsv.csv',header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into x and y with 26 features for x and label column for y.\n",
    "x = data.iloc[:,0:26].values\n",
    "y = data.iloc[:,26].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the data with the help of standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_obj = StandardScaler()\n",
    "scalardata = std_obj.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.36605999,  3.64625755,  1.82429339, ..., -0.713829  ,\n",
       "         1.08919582,  2.41831966],\n",
       "       [ 0.52304898,  1.73878691,  1.7811252 , ...,  0.5610166 ,\n",
       "         0.37054206,  1.19746668],\n",
       "       [ 1.79844063,  3.48073324,  1.21993876, ..., -1.08394547,\n",
       "         1.43313397,  1.93585423],\n",
       "       ...,\n",
       "       [ 0.28829282,  0.0047227 ,  0.20116951, ..., -0.9468653 ,\n",
       "         0.29898446, -0.25384678],\n",
       "       [ 0.01849843, -0.48396813,  0.20980315, ...,  0.5610166 ,\n",
       "        -0.78130449,  0.29782208],\n",
       "       [-0.18121949, -0.26326904, -0.50678877, ..., -0.60416487,\n",
       "         0.17279686, -0.29562998]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing the standardized data\n",
    "scalardata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing sklearn function for pca\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying PCA to reduce dimensions\n",
    "pca = PCA(n_components=None)\n",
    "pca.fit(scalardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.30253200e+01, -1.14781184e+00,  3.14124897e+00, ...,\n",
       "         2.34992369e-02, -7.94829918e-02, -1.38139287e-16],\n",
       "       [ 6.26627658e+00,  7.57363931e-01,  1.31019157e+00, ...,\n",
       "        -3.10514907e-01,  1.14777806e-01,  2.65901416e-17],\n",
       "       [ 1.15583348e+01, -2.03078801e+00,  2.90010287e+00, ...,\n",
       "         9.45394393e-02,  2.52975171e-02,  1.99078257e-15],\n",
       "       ...,\n",
       "       [ 2.22099084e-01, -1.35465740e+00, -1.74992052e+00, ...,\n",
       "        -3.35926455e-01,  1.22109137e-01,  1.45004363e-16],\n",
       "       [-1.38280353e+00,  1.35296677e+00, -1.64848723e+00, ...,\n",
       "         1.28039540e-01,  1.22380783e-01,  1.13481539e-15],\n",
       "       [-1.40868255e+00, -2.51507218e-01, -1.13344358e+00, ...,\n",
       "         1.37654205e-01,  1.37549301e-01, -1.88290524e-15]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scalardata = pca.transform(scalardata)\n",
    "new_scalardata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 26)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scalardata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scalardata = pd.DataFrame(new_scalardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13.025320</td>\n",
       "      <td>-1.147812</td>\n",
       "      <td>3.141249</td>\n",
       "      <td>-1.407203</td>\n",
       "      <td>-0.618123</td>\n",
       "      <td>0.269438</td>\n",
       "      <td>-0.285013</td>\n",
       "      <td>-1.000018</td>\n",
       "      <td>-0.262830</td>\n",
       "      <td>-0.126182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107763</td>\n",
       "      <td>0.055629</td>\n",
       "      <td>0.042797</td>\n",
       "      <td>0.015883</td>\n",
       "      <td>-0.268684</td>\n",
       "      <td>-0.126791</td>\n",
       "      <td>-0.084446</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>-0.079483</td>\n",
       "      <td>-1.381393e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.266277</td>\n",
       "      <td>0.757364</td>\n",
       "      <td>1.310192</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.253008</td>\n",
       "      <td>1.487062</td>\n",
       "      <td>-0.765486</td>\n",
       "      <td>-0.255812</td>\n",
       "      <td>-0.112504</td>\n",
       "      <td>0.236247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124229</td>\n",
       "      <td>-0.124303</td>\n",
       "      <td>-0.181518</td>\n",
       "      <td>-0.275319</td>\n",
       "      <td>0.167695</td>\n",
       "      <td>-0.106256</td>\n",
       "      <td>0.193449</td>\n",
       "      <td>-0.310515</td>\n",
       "      <td>0.114778</td>\n",
       "      <td>2.659014e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11.558335</td>\n",
       "      <td>-2.030788</td>\n",
       "      <td>2.900103</td>\n",
       "      <td>-2.003131</td>\n",
       "      <td>-0.734042</td>\n",
       "      <td>0.340757</td>\n",
       "      <td>0.130253</td>\n",
       "      <td>-0.802580</td>\n",
       "      <td>-0.616567</td>\n",
       "      <td>-0.089366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050795</td>\n",
       "      <td>-0.283725</td>\n",
       "      <td>0.196271</td>\n",
       "      <td>0.088146</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>-0.150540</td>\n",
       "      <td>-0.082788</td>\n",
       "      <td>0.094539</td>\n",
       "      <td>0.025298</td>\n",
       "      <td>1.990783e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.517733</td>\n",
       "      <td>-2.122113</td>\n",
       "      <td>0.406237</td>\n",
       "      <td>-0.566486</td>\n",
       "      <td>0.053056</td>\n",
       "      <td>1.042495</td>\n",
       "      <td>0.447386</td>\n",
       "      <td>-0.084668</td>\n",
       "      <td>-0.423999</td>\n",
       "      <td>0.411282</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015877</td>\n",
       "      <td>-0.087901</td>\n",
       "      <td>-0.064072</td>\n",
       "      <td>-0.086039</td>\n",
       "      <td>-0.127374</td>\n",
       "      <td>0.139301</td>\n",
       "      <td>-0.028043</td>\n",
       "      <td>0.017769</td>\n",
       "      <td>-0.099876</td>\n",
       "      <td>3.934728e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.353095</td>\n",
       "      <td>-0.748050</td>\n",
       "      <td>1.083581</td>\n",
       "      <td>-0.864552</td>\n",
       "      <td>0.356737</td>\n",
       "      <td>0.956668</td>\n",
       "      <td>-0.078045</td>\n",
       "      <td>-0.071524</td>\n",
       "      <td>0.226781</td>\n",
       "      <td>-0.177651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284428</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.421424</td>\n",
       "      <td>0.195657</td>\n",
       "      <td>-0.114247</td>\n",
       "      <td>0.027879</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>-0.065778</td>\n",
       "      <td>0.075370</td>\n",
       "      <td>2.489436e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5995</td>\n",
       "      <td>-4.298184</td>\n",
       "      <td>1.694826</td>\n",
       "      <td>-0.685913</td>\n",
       "      <td>-0.753854</td>\n",
       "      <td>1.156289</td>\n",
       "      <td>-0.119243</td>\n",
       "      <td>0.339126</td>\n",
       "      <td>-0.175940</td>\n",
       "      <td>0.014415</td>\n",
       "      <td>0.236920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.274034</td>\n",
       "      <td>-0.193388</td>\n",
       "      <td>0.127095</td>\n",
       "      <td>-0.204722</td>\n",
       "      <td>-0.512110</td>\n",
       "      <td>-0.043807</td>\n",
       "      <td>-0.129971</td>\n",
       "      <td>-0.112594</td>\n",
       "      <td>-0.071441</td>\n",
       "      <td>6.169344e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5996</td>\n",
       "      <td>2.448154</td>\n",
       "      <td>-0.412929</td>\n",
       "      <td>-1.481050</td>\n",
       "      <td>0.328945</td>\n",
       "      <td>-0.733546</td>\n",
       "      <td>-0.116789</td>\n",
       "      <td>0.706199</td>\n",
       "      <td>0.302345</td>\n",
       "      <td>-0.015092</td>\n",
       "      <td>0.088344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020756</td>\n",
       "      <td>-0.167451</td>\n",
       "      <td>0.063203</td>\n",
       "      <td>0.047793</td>\n",
       "      <td>0.219792</td>\n",
       "      <td>0.260250</td>\n",
       "      <td>-0.049955</td>\n",
       "      <td>0.113507</td>\n",
       "      <td>-0.137939</td>\n",
       "      <td>4.992440e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5997</td>\n",
       "      <td>0.222099</td>\n",
       "      <td>-1.354657</td>\n",
       "      <td>-1.749921</td>\n",
       "      <td>0.102923</td>\n",
       "      <td>0.022114</td>\n",
       "      <td>-0.341273</td>\n",
       "      <td>0.246870</td>\n",
       "      <td>-0.116025</td>\n",
       "      <td>-0.328617</td>\n",
       "      <td>0.411589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209412</td>\n",
       "      <td>0.169790</td>\n",
       "      <td>-0.185954</td>\n",
       "      <td>-0.327820</td>\n",
       "      <td>-0.042437</td>\n",
       "      <td>-0.140284</td>\n",
       "      <td>-0.058423</td>\n",
       "      <td>-0.335926</td>\n",
       "      <td>0.122109</td>\n",
       "      <td>1.450044e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5998</td>\n",
       "      <td>-1.382804</td>\n",
       "      <td>1.352967</td>\n",
       "      <td>-1.648487</td>\n",
       "      <td>-0.993851</td>\n",
       "      <td>0.127188</td>\n",
       "      <td>0.234405</td>\n",
       "      <td>-0.267140</td>\n",
       "      <td>-0.135703</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>-0.145477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332787</td>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.240599</td>\n",
       "      <td>-0.488706</td>\n",
       "      <td>-0.090020</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>-0.193956</td>\n",
       "      <td>0.128040</td>\n",
       "      <td>0.122381</td>\n",
       "      <td>1.134815e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5999</td>\n",
       "      <td>-1.408683</td>\n",
       "      <td>-0.251507</td>\n",
       "      <td>-1.133444</td>\n",
       "      <td>-1.673723</td>\n",
       "      <td>-0.505760</td>\n",
       "      <td>-0.225619</td>\n",
       "      <td>0.297823</td>\n",
       "      <td>0.267031</td>\n",
       "      <td>-0.065843</td>\n",
       "      <td>0.216497</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171015</td>\n",
       "      <td>0.477406</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>-0.393922</td>\n",
       "      <td>0.365637</td>\n",
       "      <td>-0.171328</td>\n",
       "      <td>0.062658</td>\n",
       "      <td>0.137654</td>\n",
       "      <td>0.137549</td>\n",
       "      <td>-1.882905e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0     13.025320 -1.147812  3.141249 -1.407203 -0.618123  0.269438 -0.285013   \n",
       "1      6.266277  0.757364  1.310192  0.204800  0.253008  1.487062 -0.765486   \n",
       "2     11.558335 -2.030788  2.900103 -2.003131 -0.734042  0.340757  0.130253   \n",
       "3      8.517733 -2.122113  0.406237 -0.566486  0.053056  1.042495  0.447386   \n",
       "4      6.353095 -0.748050  1.083581 -0.864552  0.356737  0.956668 -0.078045   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "5995  -4.298184  1.694826 -0.685913 -0.753854  1.156289 -0.119243  0.339126   \n",
       "5996   2.448154 -0.412929 -1.481050  0.328945 -0.733546 -0.116789  0.706199   \n",
       "5997   0.222099 -1.354657 -1.749921  0.102923  0.022114 -0.341273  0.246870   \n",
       "5998  -1.382804  1.352967 -1.648487 -0.993851  0.127188  0.234405 -0.267140   \n",
       "5999  -1.408683 -0.251507 -1.133444 -1.673723 -0.505760 -0.225619  0.297823   \n",
       "\n",
       "            7         8         9   ...        16        17        18  \\\n",
       "0    -1.000018 -0.262830 -0.126182  ...  0.107763  0.055629  0.042797   \n",
       "1    -0.255812 -0.112504  0.236247  ...  0.124229 -0.124303 -0.181518   \n",
       "2    -0.802580 -0.616567 -0.089366  ...  0.050795 -0.283725  0.196271   \n",
       "3    -0.084668 -0.423999  0.411282  ... -0.015877 -0.087901 -0.064072   \n",
       "4    -0.071524  0.226781 -0.177651  ...  0.284428  0.048900  0.421424   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5995 -0.175940  0.014415  0.236920  ... -0.274034 -0.193388  0.127095   \n",
       "5996  0.302345 -0.015092  0.088344  ... -0.020756 -0.167451  0.063203   \n",
       "5997 -0.116025 -0.328617  0.411589  ...  0.209412  0.169790 -0.185954   \n",
       "5998 -0.135703  0.000293 -0.145477  ...  0.332787  0.009730  0.240599   \n",
       "5999  0.267031 -0.065843  0.216497  ... -0.171015  0.477406  0.007619   \n",
       "\n",
       "            19        20        21        22        23        24            25  \n",
       "0     0.015883 -0.268684 -0.126791 -0.084446  0.023499 -0.079483 -1.381393e-16  \n",
       "1    -0.275319  0.167695 -0.106256  0.193449 -0.310515  0.114778  2.659014e-17  \n",
       "2     0.088146  0.001811 -0.150540 -0.082788  0.094539  0.025298  1.990783e-15  \n",
       "3    -0.086039 -0.127374  0.139301 -0.028043  0.017769 -0.099876  3.934728e-16  \n",
       "4     0.195657 -0.114247  0.027879  0.243750 -0.065778  0.075370  2.489436e-15  \n",
       "...        ...       ...       ...       ...       ...       ...           ...  \n",
       "5995 -0.204722 -0.512110 -0.043807 -0.129971 -0.112594 -0.071441  6.169344e-16  \n",
       "5996  0.047793  0.219792  0.260250 -0.049955  0.113507 -0.137939  4.992440e-16  \n",
       "5997 -0.327820 -0.042437 -0.140284 -0.058423 -0.335926  0.122109  1.450044e-16  \n",
       "5998 -0.488706 -0.090020 -0.000818 -0.193956  0.128040  0.122381  1.134815e-15  \n",
       "5999 -0.393922  0.365637 -0.171328  0.062658  0.137654  0.137549 -1.882905e-15  \n",
       "\n",
       "[6000 rows x 26 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scalardata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 26)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scalardata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Initially the explained variance sum of the full data with 26 features comes out to be 1.\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=18, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choosing only 18 columns from the data.\n",
    "pca = PCA(n_components=18)\n",
    "pca.fit(scalardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the pickle file of the pca model to the drive\n",
    "filename = 'C:\\\\Users\\\\omkar\\\\OneDrive\\\\Desktop\\\\College work\\\\TY\\\\ML FINAL PROJECT\\\\PCA_Model.sav'\n",
    "pickle.dump(pca, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.30253200e+01, -1.14781184e+00,  3.14124897e+00, ...,\n",
       "        -1.55866740e-01,  1.07762930e-01,  5.56291061e-02],\n",
       "       [ 6.26627658e+00,  7.57363931e-01,  1.31019157e+00, ...,\n",
       "        -2.76192695e-01,  1.24229211e-01, -1.24302894e-01],\n",
       "       [ 1.15583348e+01, -2.03078801e+00,  2.90010287e+00, ...,\n",
       "        -2.13978822e-01,  5.07951056e-02, -2.83725270e-01],\n",
       "       ...,\n",
       "       [ 2.22099084e-01, -1.35465740e+00, -1.74992052e+00, ...,\n",
       "        -4.91427849e-02,  2.09412375e-01,  1.69790062e-01],\n",
       "       [-1.38280353e+00,  1.35296677e+00, -1.64848723e+00, ...,\n",
       "         4.77581114e-01,  3.32787004e-01,  9.72999184e-03],\n",
       "       [-1.40868255e+00, -2.51507218e-01, -1.13344358e+00, ...,\n",
       "         1.76174573e-01, -1.71014845e-01,  4.77405786e-01]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scalardata = pca.transform(scalardata)\n",
    "new_scalardata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 18)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scalardata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.990360708779925\n"
     ]
    }
   ],
   "source": [
    "#explained variance sum of the data with 18 columns comes out to be 99%.\n",
    "print(pca.explained_variance_ratio_.sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13.025320</td>\n",
       "      <td>-1.147812</td>\n",
       "      <td>3.141249</td>\n",
       "      <td>-1.407203</td>\n",
       "      <td>-0.618123</td>\n",
       "      <td>0.269438</td>\n",
       "      <td>-0.285013</td>\n",
       "      <td>-1.000018</td>\n",
       "      <td>-0.262830</td>\n",
       "      <td>-0.126182</td>\n",
       "      <td>0.451391</td>\n",
       "      <td>0.250481</td>\n",
       "      <td>-0.449014</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>-0.288916</td>\n",
       "      <td>-0.155867</td>\n",
       "      <td>0.107763</td>\n",
       "      <td>0.055629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.266277</td>\n",
       "      <td>0.757364</td>\n",
       "      <td>1.310192</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.253008</td>\n",
       "      <td>1.487062</td>\n",
       "      <td>-0.765486</td>\n",
       "      <td>-0.255812</td>\n",
       "      <td>-0.112504</td>\n",
       "      <td>0.236247</td>\n",
       "      <td>-0.035694</td>\n",
       "      <td>-0.094230</td>\n",
       "      <td>0.215514</td>\n",
       "      <td>0.197993</td>\n",
       "      <td>0.107270</td>\n",
       "      <td>-0.276193</td>\n",
       "      <td>0.124229</td>\n",
       "      <td>-0.124303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11.558335</td>\n",
       "      <td>-2.030788</td>\n",
       "      <td>2.900103</td>\n",
       "      <td>-2.003131</td>\n",
       "      <td>-0.734042</td>\n",
       "      <td>0.340757</td>\n",
       "      <td>0.130253</td>\n",
       "      <td>-0.802580</td>\n",
       "      <td>-0.616567</td>\n",
       "      <td>-0.089366</td>\n",
       "      <td>-0.140864</td>\n",
       "      <td>-0.115965</td>\n",
       "      <td>0.074073</td>\n",
       "      <td>0.106007</td>\n",
       "      <td>0.095371</td>\n",
       "      <td>-0.213979</td>\n",
       "      <td>0.050795</td>\n",
       "      <td>-0.283725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.517733</td>\n",
       "      <td>-2.122113</td>\n",
       "      <td>0.406237</td>\n",
       "      <td>-0.566486</td>\n",
       "      <td>0.053056</td>\n",
       "      <td>1.042495</td>\n",
       "      <td>0.447386</td>\n",
       "      <td>-0.084668</td>\n",
       "      <td>-0.423999</td>\n",
       "      <td>0.411282</td>\n",
       "      <td>-0.151000</td>\n",
       "      <td>-0.166272</td>\n",
       "      <td>-0.166718</td>\n",
       "      <td>-0.202987</td>\n",
       "      <td>0.350999</td>\n",
       "      <td>0.059044</td>\n",
       "      <td>-0.015877</td>\n",
       "      <td>-0.087901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.353095</td>\n",
       "      <td>-0.748050</td>\n",
       "      <td>1.083581</td>\n",
       "      <td>-0.864552</td>\n",
       "      <td>0.356737</td>\n",
       "      <td>0.956668</td>\n",
       "      <td>-0.078045</td>\n",
       "      <td>-0.071524</td>\n",
       "      <td>0.226781</td>\n",
       "      <td>-0.177651</td>\n",
       "      <td>0.035830</td>\n",
       "      <td>0.298667</td>\n",
       "      <td>0.026282</td>\n",
       "      <td>0.189246</td>\n",
       "      <td>0.466544</td>\n",
       "      <td>-0.371295</td>\n",
       "      <td>0.284428</td>\n",
       "      <td>0.048900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5995</td>\n",
       "      <td>-4.298184</td>\n",
       "      <td>1.694826</td>\n",
       "      <td>-0.685913</td>\n",
       "      <td>-0.753854</td>\n",
       "      <td>1.156289</td>\n",
       "      <td>-0.119243</td>\n",
       "      <td>0.339126</td>\n",
       "      <td>-0.175940</td>\n",
       "      <td>0.014415</td>\n",
       "      <td>0.236920</td>\n",
       "      <td>0.421853</td>\n",
       "      <td>-0.320831</td>\n",
       "      <td>0.331370</td>\n",
       "      <td>0.326219</td>\n",
       "      <td>-0.410505</td>\n",
       "      <td>-0.408616</td>\n",
       "      <td>-0.274034</td>\n",
       "      <td>-0.193388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5996</td>\n",
       "      <td>2.448154</td>\n",
       "      <td>-0.412929</td>\n",
       "      <td>-1.481050</td>\n",
       "      <td>0.328945</td>\n",
       "      <td>-0.733546</td>\n",
       "      <td>-0.116789</td>\n",
       "      <td>0.706199</td>\n",
       "      <td>0.302345</td>\n",
       "      <td>-0.015092</td>\n",
       "      <td>0.088344</td>\n",
       "      <td>0.098513</td>\n",
       "      <td>0.324503</td>\n",
       "      <td>-0.244092</td>\n",
       "      <td>-0.442976</td>\n",
       "      <td>0.105378</td>\n",
       "      <td>0.107065</td>\n",
       "      <td>-0.020756</td>\n",
       "      <td>-0.167451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5997</td>\n",
       "      <td>0.222099</td>\n",
       "      <td>-1.354657</td>\n",
       "      <td>-1.749921</td>\n",
       "      <td>0.102923</td>\n",
       "      <td>0.022114</td>\n",
       "      <td>-0.341273</td>\n",
       "      <td>0.246870</td>\n",
       "      <td>-0.116025</td>\n",
       "      <td>-0.328617</td>\n",
       "      <td>0.411589</td>\n",
       "      <td>0.636721</td>\n",
       "      <td>-0.531026</td>\n",
       "      <td>-0.058351</td>\n",
       "      <td>0.822338</td>\n",
       "      <td>0.116245</td>\n",
       "      <td>-0.049143</td>\n",
       "      <td>0.209412</td>\n",
       "      <td>0.169790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5998</td>\n",
       "      <td>-1.382804</td>\n",
       "      <td>1.352967</td>\n",
       "      <td>-1.648487</td>\n",
       "      <td>-0.993851</td>\n",
       "      <td>0.127188</td>\n",
       "      <td>0.234405</td>\n",
       "      <td>-0.267140</td>\n",
       "      <td>-0.135703</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>-0.145477</td>\n",
       "      <td>-0.054742</td>\n",
       "      <td>-0.352817</td>\n",
       "      <td>-0.083453</td>\n",
       "      <td>0.119906</td>\n",
       "      <td>-0.220282</td>\n",
       "      <td>0.477581</td>\n",
       "      <td>0.332787</td>\n",
       "      <td>0.009730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5999</td>\n",
       "      <td>-1.408683</td>\n",
       "      <td>-0.251507</td>\n",
       "      <td>-1.133444</td>\n",
       "      <td>-1.673723</td>\n",
       "      <td>-0.505760</td>\n",
       "      <td>-0.225619</td>\n",
       "      <td>0.297823</td>\n",
       "      <td>0.267031</td>\n",
       "      <td>-0.065843</td>\n",
       "      <td>0.216497</td>\n",
       "      <td>0.252764</td>\n",
       "      <td>-0.122092</td>\n",
       "      <td>0.153038</td>\n",
       "      <td>-0.273876</td>\n",
       "      <td>-0.439021</td>\n",
       "      <td>0.176175</td>\n",
       "      <td>-0.171015</td>\n",
       "      <td>0.477406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     13.025320 -1.147812  3.141249 -1.407203 -0.618123  0.269438 -0.285013   \n",
       "1      6.266277  0.757364  1.310192  0.204800  0.253008  1.487062 -0.765486   \n",
       "2     11.558335 -2.030788  2.900103 -2.003131 -0.734042  0.340757  0.130253   \n",
       "3      8.517733 -2.122113  0.406237 -0.566486  0.053056  1.042495  0.447386   \n",
       "4      6.353095 -0.748050  1.083581 -0.864552  0.356737  0.956668 -0.078045   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "5995  -4.298184  1.694826 -0.685913 -0.753854  1.156289 -0.119243  0.339126   \n",
       "5996   2.448154 -0.412929 -1.481050  0.328945 -0.733546 -0.116789  0.706199   \n",
       "5997   0.222099 -1.354657 -1.749921  0.102923  0.022114 -0.341273  0.246870   \n",
       "5998  -1.382804  1.352967 -1.648487 -0.993851  0.127188  0.234405 -0.267140   \n",
       "5999  -1.408683 -0.251507 -1.133444 -1.673723 -0.505760 -0.225619  0.297823   \n",
       "\n",
       "             7         8         9        10        11        12        13  \\\n",
       "0    -1.000018 -0.262830 -0.126182  0.451391  0.250481 -0.449014  0.012944   \n",
       "1    -0.255812 -0.112504  0.236247 -0.035694 -0.094230  0.215514  0.197993   \n",
       "2    -0.802580 -0.616567 -0.089366 -0.140864 -0.115965  0.074073  0.106007   \n",
       "3    -0.084668 -0.423999  0.411282 -0.151000 -0.166272 -0.166718 -0.202987   \n",
       "4    -0.071524  0.226781 -0.177651  0.035830  0.298667  0.026282  0.189246   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5995 -0.175940  0.014415  0.236920  0.421853 -0.320831  0.331370  0.326219   \n",
       "5996  0.302345 -0.015092  0.088344  0.098513  0.324503 -0.244092 -0.442976   \n",
       "5997 -0.116025 -0.328617  0.411589  0.636721 -0.531026 -0.058351  0.822338   \n",
       "5998 -0.135703  0.000293 -0.145477 -0.054742 -0.352817 -0.083453  0.119906   \n",
       "5999  0.267031 -0.065843  0.216497  0.252764 -0.122092  0.153038 -0.273876   \n",
       "\n",
       "            14        15        16        17  \n",
       "0    -0.288916 -0.155867  0.107763  0.055629  \n",
       "1     0.107270 -0.276193  0.124229 -0.124303  \n",
       "2     0.095371 -0.213979  0.050795 -0.283725  \n",
       "3     0.350999  0.059044 -0.015877 -0.087901  \n",
       "4     0.466544 -0.371295  0.284428  0.048900  \n",
       "...        ...       ...       ...       ...  \n",
       "5995 -0.410505 -0.408616 -0.274034 -0.193388  \n",
       "5996  0.105378  0.107065 -0.020756 -0.167451  \n",
       "5997  0.116245 -0.049143  0.209412  0.169790  \n",
       "5998 -0.220282  0.477581  0.332787  0.009730  \n",
       "5999 -0.439021  0.176175 -0.171015  0.477406  \n",
       "\n",
       "[6000 rows x 18 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting the data into dataframe\n",
    "new_scalardata = pd.DataFrame(new_scalardata)\n",
    "new_scalardata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13.025320</td>\n",
       "      <td>-1.147812</td>\n",
       "      <td>3.141249</td>\n",
       "      <td>-1.407203</td>\n",
       "      <td>-0.618123</td>\n",
       "      <td>0.269438</td>\n",
       "      <td>-0.285013</td>\n",
       "      <td>-1.000018</td>\n",
       "      <td>-0.262830</td>\n",
       "      <td>-0.126182</td>\n",
       "      <td>0.451391</td>\n",
       "      <td>0.250481</td>\n",
       "      <td>-0.449014</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>-0.288916</td>\n",
       "      <td>-0.155867</td>\n",
       "      <td>0.107763</td>\n",
       "      <td>0.055629</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.266277</td>\n",
       "      <td>0.757364</td>\n",
       "      <td>1.310192</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.253008</td>\n",
       "      <td>1.487062</td>\n",
       "      <td>-0.765486</td>\n",
       "      <td>-0.255812</td>\n",
       "      <td>-0.112504</td>\n",
       "      <td>0.236247</td>\n",
       "      <td>-0.035694</td>\n",
       "      <td>-0.094230</td>\n",
       "      <td>0.215514</td>\n",
       "      <td>0.197993</td>\n",
       "      <td>0.107270</td>\n",
       "      <td>-0.276193</td>\n",
       "      <td>0.124229</td>\n",
       "      <td>-0.124303</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11.558335</td>\n",
       "      <td>-2.030788</td>\n",
       "      <td>2.900103</td>\n",
       "      <td>-2.003131</td>\n",
       "      <td>-0.734042</td>\n",
       "      <td>0.340757</td>\n",
       "      <td>0.130253</td>\n",
       "      <td>-0.802580</td>\n",
       "      <td>-0.616567</td>\n",
       "      <td>-0.089366</td>\n",
       "      <td>-0.140864</td>\n",
       "      <td>-0.115965</td>\n",
       "      <td>0.074073</td>\n",
       "      <td>0.106007</td>\n",
       "      <td>0.095371</td>\n",
       "      <td>-0.213979</td>\n",
       "      <td>0.050795</td>\n",
       "      <td>-0.283725</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.517733</td>\n",
       "      <td>-2.122113</td>\n",
       "      <td>0.406237</td>\n",
       "      <td>-0.566486</td>\n",
       "      <td>0.053056</td>\n",
       "      <td>1.042495</td>\n",
       "      <td>0.447386</td>\n",
       "      <td>-0.084668</td>\n",
       "      <td>-0.423999</td>\n",
       "      <td>0.411282</td>\n",
       "      <td>-0.151000</td>\n",
       "      <td>-0.166272</td>\n",
       "      <td>-0.166718</td>\n",
       "      <td>-0.202987</td>\n",
       "      <td>0.350999</td>\n",
       "      <td>0.059044</td>\n",
       "      <td>-0.015877</td>\n",
       "      <td>-0.087901</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.353095</td>\n",
       "      <td>-0.748050</td>\n",
       "      <td>1.083581</td>\n",
       "      <td>-0.864552</td>\n",
       "      <td>0.356737</td>\n",
       "      <td>0.956668</td>\n",
       "      <td>-0.078045</td>\n",
       "      <td>-0.071524</td>\n",
       "      <td>0.226781</td>\n",
       "      <td>-0.177651</td>\n",
       "      <td>0.035830</td>\n",
       "      <td>0.298667</td>\n",
       "      <td>0.026282</td>\n",
       "      <td>0.189246</td>\n",
       "      <td>0.466544</td>\n",
       "      <td>-0.371295</td>\n",
       "      <td>0.284428</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5995</td>\n",
       "      <td>-4.298184</td>\n",
       "      <td>1.694826</td>\n",
       "      <td>-0.685913</td>\n",
       "      <td>-0.753854</td>\n",
       "      <td>1.156289</td>\n",
       "      <td>-0.119243</td>\n",
       "      <td>0.339126</td>\n",
       "      <td>-0.175940</td>\n",
       "      <td>0.014415</td>\n",
       "      <td>0.236920</td>\n",
       "      <td>0.421853</td>\n",
       "      <td>-0.320831</td>\n",
       "      <td>0.331370</td>\n",
       "      <td>0.326219</td>\n",
       "      <td>-0.410505</td>\n",
       "      <td>-0.408616</td>\n",
       "      <td>-0.274034</td>\n",
       "      <td>-0.193388</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5996</td>\n",
       "      <td>2.448154</td>\n",
       "      <td>-0.412929</td>\n",
       "      <td>-1.481050</td>\n",
       "      <td>0.328945</td>\n",
       "      <td>-0.733546</td>\n",
       "      <td>-0.116789</td>\n",
       "      <td>0.706199</td>\n",
       "      <td>0.302345</td>\n",
       "      <td>-0.015092</td>\n",
       "      <td>0.088344</td>\n",
       "      <td>0.098513</td>\n",
       "      <td>0.324503</td>\n",
       "      <td>-0.244092</td>\n",
       "      <td>-0.442976</td>\n",
       "      <td>0.105378</td>\n",
       "      <td>0.107065</td>\n",
       "      <td>-0.020756</td>\n",
       "      <td>-0.167451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5997</td>\n",
       "      <td>0.222099</td>\n",
       "      <td>-1.354657</td>\n",
       "      <td>-1.749921</td>\n",
       "      <td>0.102923</td>\n",
       "      <td>0.022114</td>\n",
       "      <td>-0.341273</td>\n",
       "      <td>0.246870</td>\n",
       "      <td>-0.116025</td>\n",
       "      <td>-0.328617</td>\n",
       "      <td>0.411589</td>\n",
       "      <td>0.636721</td>\n",
       "      <td>-0.531026</td>\n",
       "      <td>-0.058351</td>\n",
       "      <td>0.822338</td>\n",
       "      <td>0.116245</td>\n",
       "      <td>-0.049143</td>\n",
       "      <td>0.209412</td>\n",
       "      <td>0.169790</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5998</td>\n",
       "      <td>-1.382804</td>\n",
       "      <td>1.352967</td>\n",
       "      <td>-1.648487</td>\n",
       "      <td>-0.993851</td>\n",
       "      <td>0.127188</td>\n",
       "      <td>0.234405</td>\n",
       "      <td>-0.267140</td>\n",
       "      <td>-0.135703</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>-0.145477</td>\n",
       "      <td>-0.054742</td>\n",
       "      <td>-0.352817</td>\n",
       "      <td>-0.083453</td>\n",
       "      <td>0.119906</td>\n",
       "      <td>-0.220282</td>\n",
       "      <td>0.477581</td>\n",
       "      <td>0.332787</td>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5999</td>\n",
       "      <td>-1.408683</td>\n",
       "      <td>-0.251507</td>\n",
       "      <td>-1.133444</td>\n",
       "      <td>-1.673723</td>\n",
       "      <td>-0.505760</td>\n",
       "      <td>-0.225619</td>\n",
       "      <td>0.297823</td>\n",
       "      <td>0.267031</td>\n",
       "      <td>-0.065843</td>\n",
       "      <td>0.216497</td>\n",
       "      <td>0.252764</td>\n",
       "      <td>-0.122092</td>\n",
       "      <td>0.153038</td>\n",
       "      <td>-0.273876</td>\n",
       "      <td>-0.439021</td>\n",
       "      <td>0.176175</td>\n",
       "      <td>-0.171015</td>\n",
       "      <td>0.477406</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0     13.025320 -1.147812  3.141249 -1.407203 -0.618123  0.269438 -0.285013   \n",
       "1      6.266277  0.757364  1.310192  0.204800  0.253008  1.487062 -0.765486   \n",
       "2     11.558335 -2.030788  2.900103 -2.003131 -0.734042  0.340757  0.130253   \n",
       "3      8.517733 -2.122113  0.406237 -0.566486  0.053056  1.042495  0.447386   \n",
       "4      6.353095 -0.748050  1.083581 -0.864552  0.356737  0.956668 -0.078045   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "5995  -4.298184  1.694826 -0.685913 -0.753854  1.156289 -0.119243  0.339126   \n",
       "5996   2.448154 -0.412929 -1.481050  0.328945 -0.733546 -0.116789  0.706199   \n",
       "5997   0.222099 -1.354657 -1.749921  0.102923  0.022114 -0.341273  0.246870   \n",
       "5998  -1.382804  1.352967 -1.648487 -0.993851  0.127188  0.234405 -0.267140   \n",
       "5999  -1.408683 -0.251507 -1.133444 -1.673723 -0.505760 -0.225619  0.297823   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "0    -1.000018 -0.262830 -0.126182  0.451391  0.250481 -0.449014  0.012944   \n",
       "1    -0.255812 -0.112504  0.236247 -0.035694 -0.094230  0.215514  0.197993   \n",
       "2    -0.802580 -0.616567 -0.089366 -0.140864 -0.115965  0.074073  0.106007   \n",
       "3    -0.084668 -0.423999  0.411282 -0.151000 -0.166272 -0.166718 -0.202987   \n",
       "4    -0.071524  0.226781 -0.177651  0.035830  0.298667  0.026282  0.189246   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5995 -0.175940  0.014415  0.236920  0.421853 -0.320831  0.331370  0.326219   \n",
       "5996  0.302345 -0.015092  0.088344  0.098513  0.324503 -0.244092 -0.442976   \n",
       "5997 -0.116025 -0.328617  0.411589  0.636721 -0.531026 -0.058351  0.822338   \n",
       "5998 -0.135703  0.000293 -0.145477 -0.054742 -0.352817 -0.083453  0.119906   \n",
       "5999  0.267031 -0.065843  0.216497  0.252764 -0.122092  0.153038 -0.273876   \n",
       "\n",
       "            14        15        16        17   0   \n",
       "0    -0.288916 -0.155867  0.107763  0.055629  1.0  \n",
       "1     0.107270 -0.276193  0.124229 -0.124303  1.0  \n",
       "2     0.095371 -0.213979  0.050795 -0.283725  1.0  \n",
       "3     0.350999  0.059044 -0.015877 -0.087901  1.0  \n",
       "4     0.466544 -0.371295  0.284428  0.048900  1.0  \n",
       "...        ...       ...       ...       ...  ...  \n",
       "5995 -0.410505 -0.408616 -0.274034 -0.193388  0.0  \n",
       "5996  0.105378  0.107065 -0.020756 -0.167451  0.0  \n",
       "5997  0.116245 -0.049143  0.209412  0.169790  0.0  \n",
       "5998 -0.220282  0.477581  0.332787  0.009730  0.0  \n",
       "5999 -0.439021  0.176175 -0.171015  0.477406  0.0  \n",
       "\n",
       "[6000 rows x 19 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#appending the label column to the dataframe.\n",
    "label_column = pd.concat([new_scalardata, pd.DataFrame(y)],axis=1)\n",
    "label_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the dataframe as as csv file.\n",
    "csv_data=label_column.to_csv('C:\\\\Users\\\\omkar\\\\OneDrive\\\\Desktop\\\\College work\\\\TY\\\\ML FINAL PROJECT\\\\FinalPCAFV.csv', mode='a',header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training , Testing and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the final training data.\n",
    "train_data = pd.read_csv('C:\\\\Users\\\\omkar\\\\OneDrive\\\\Desktop\\\\College work\\\\TY\\\\ML FINAL PROJECT\\\\FinalPCAFV.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13.025320</td>\n",
       "      <td>-1.147812</td>\n",
       "      <td>3.141249</td>\n",
       "      <td>-1.407203</td>\n",
       "      <td>-0.618123</td>\n",
       "      <td>0.269438</td>\n",
       "      <td>-0.285013</td>\n",
       "      <td>-1.000018</td>\n",
       "      <td>-0.262830</td>\n",
       "      <td>-0.126182</td>\n",
       "      <td>0.451391</td>\n",
       "      <td>0.250481</td>\n",
       "      <td>-0.449014</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>-0.288916</td>\n",
       "      <td>-0.155867</td>\n",
       "      <td>0.107763</td>\n",
       "      <td>0.055629</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.266277</td>\n",
       "      <td>0.757364</td>\n",
       "      <td>1.310192</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.253008</td>\n",
       "      <td>1.487062</td>\n",
       "      <td>-0.765486</td>\n",
       "      <td>-0.255812</td>\n",
       "      <td>-0.112504</td>\n",
       "      <td>0.236247</td>\n",
       "      <td>-0.035694</td>\n",
       "      <td>-0.094230</td>\n",
       "      <td>0.215514</td>\n",
       "      <td>0.197993</td>\n",
       "      <td>0.107270</td>\n",
       "      <td>-0.276193</td>\n",
       "      <td>0.124229</td>\n",
       "      <td>-0.124303</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11.558335</td>\n",
       "      <td>-2.030788</td>\n",
       "      <td>2.900103</td>\n",
       "      <td>-2.003131</td>\n",
       "      <td>-0.734042</td>\n",
       "      <td>0.340757</td>\n",
       "      <td>0.130253</td>\n",
       "      <td>-0.802580</td>\n",
       "      <td>-0.616567</td>\n",
       "      <td>-0.089366</td>\n",
       "      <td>-0.140864</td>\n",
       "      <td>-0.115965</td>\n",
       "      <td>0.074073</td>\n",
       "      <td>0.106007</td>\n",
       "      <td>0.095371</td>\n",
       "      <td>-0.213979</td>\n",
       "      <td>0.050795</td>\n",
       "      <td>-0.283725</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.517733</td>\n",
       "      <td>-2.122113</td>\n",
       "      <td>0.406237</td>\n",
       "      <td>-0.566486</td>\n",
       "      <td>0.053056</td>\n",
       "      <td>1.042495</td>\n",
       "      <td>0.447386</td>\n",
       "      <td>-0.084668</td>\n",
       "      <td>-0.423999</td>\n",
       "      <td>0.411282</td>\n",
       "      <td>-0.151000</td>\n",
       "      <td>-0.166272</td>\n",
       "      <td>-0.166718</td>\n",
       "      <td>-0.202987</td>\n",
       "      <td>0.350999</td>\n",
       "      <td>0.059044</td>\n",
       "      <td>-0.015877</td>\n",
       "      <td>-0.087901</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.353095</td>\n",
       "      <td>-0.748050</td>\n",
       "      <td>1.083581</td>\n",
       "      <td>-0.864552</td>\n",
       "      <td>0.356737</td>\n",
       "      <td>0.956668</td>\n",
       "      <td>-0.078045</td>\n",
       "      <td>-0.071524</td>\n",
       "      <td>0.226781</td>\n",
       "      <td>-0.177651</td>\n",
       "      <td>0.035830</td>\n",
       "      <td>0.298667</td>\n",
       "      <td>0.026282</td>\n",
       "      <td>0.189246</td>\n",
       "      <td>0.466544</td>\n",
       "      <td>-0.371295</td>\n",
       "      <td>0.284428</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5995</td>\n",
       "      <td>-4.298184</td>\n",
       "      <td>1.694826</td>\n",
       "      <td>-0.685913</td>\n",
       "      <td>-0.753854</td>\n",
       "      <td>1.156289</td>\n",
       "      <td>-0.119243</td>\n",
       "      <td>0.339126</td>\n",
       "      <td>-0.175940</td>\n",
       "      <td>0.014415</td>\n",
       "      <td>0.236920</td>\n",
       "      <td>0.421853</td>\n",
       "      <td>-0.320831</td>\n",
       "      <td>0.331370</td>\n",
       "      <td>0.326219</td>\n",
       "      <td>-0.410505</td>\n",
       "      <td>-0.408616</td>\n",
       "      <td>-0.274034</td>\n",
       "      <td>-0.193388</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5996</td>\n",
       "      <td>2.448154</td>\n",
       "      <td>-0.412929</td>\n",
       "      <td>-1.481050</td>\n",
       "      <td>0.328945</td>\n",
       "      <td>-0.733546</td>\n",
       "      <td>-0.116789</td>\n",
       "      <td>0.706199</td>\n",
       "      <td>0.302345</td>\n",
       "      <td>-0.015092</td>\n",
       "      <td>0.088344</td>\n",
       "      <td>0.098513</td>\n",
       "      <td>0.324503</td>\n",
       "      <td>-0.244092</td>\n",
       "      <td>-0.442976</td>\n",
       "      <td>0.105378</td>\n",
       "      <td>0.107065</td>\n",
       "      <td>-0.020756</td>\n",
       "      <td>-0.167451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5997</td>\n",
       "      <td>0.222099</td>\n",
       "      <td>-1.354657</td>\n",
       "      <td>-1.749921</td>\n",
       "      <td>0.102923</td>\n",
       "      <td>0.022114</td>\n",
       "      <td>-0.341273</td>\n",
       "      <td>0.246870</td>\n",
       "      <td>-0.116025</td>\n",
       "      <td>-0.328617</td>\n",
       "      <td>0.411589</td>\n",
       "      <td>0.636721</td>\n",
       "      <td>-0.531026</td>\n",
       "      <td>-0.058351</td>\n",
       "      <td>0.822338</td>\n",
       "      <td>0.116245</td>\n",
       "      <td>-0.049143</td>\n",
       "      <td>0.209412</td>\n",
       "      <td>0.169790</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5998</td>\n",
       "      <td>-1.382804</td>\n",
       "      <td>1.352967</td>\n",
       "      <td>-1.648487</td>\n",
       "      <td>-0.993851</td>\n",
       "      <td>0.127188</td>\n",
       "      <td>0.234405</td>\n",
       "      <td>-0.267140</td>\n",
       "      <td>-0.135703</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>-0.145477</td>\n",
       "      <td>-0.054742</td>\n",
       "      <td>-0.352817</td>\n",
       "      <td>-0.083453</td>\n",
       "      <td>0.119906</td>\n",
       "      <td>-0.220282</td>\n",
       "      <td>0.477581</td>\n",
       "      <td>0.332787</td>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5999</td>\n",
       "      <td>-1.408683</td>\n",
       "      <td>-0.251507</td>\n",
       "      <td>-1.133444</td>\n",
       "      <td>-1.673723</td>\n",
       "      <td>-0.505760</td>\n",
       "      <td>-0.225619</td>\n",
       "      <td>0.297823</td>\n",
       "      <td>0.267031</td>\n",
       "      <td>-0.065843</td>\n",
       "      <td>0.216497</td>\n",
       "      <td>0.252764</td>\n",
       "      <td>-0.122092</td>\n",
       "      <td>0.153038</td>\n",
       "      <td>-0.273876</td>\n",
       "      <td>-0.439021</td>\n",
       "      <td>0.176175</td>\n",
       "      <td>-0.171015</td>\n",
       "      <td>0.477406</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0     13.025320 -1.147812  3.141249 -1.407203 -0.618123  0.269438 -0.285013   \n",
       "1      6.266277  0.757364  1.310192  0.204800  0.253008  1.487062 -0.765486   \n",
       "2     11.558335 -2.030788  2.900103 -2.003131 -0.734042  0.340757  0.130253   \n",
       "3      8.517733 -2.122113  0.406237 -0.566486  0.053056  1.042495  0.447386   \n",
       "4      6.353095 -0.748050  1.083581 -0.864552  0.356737  0.956668 -0.078045   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "5995  -4.298184  1.694826 -0.685913 -0.753854  1.156289 -0.119243  0.339126   \n",
       "5996   2.448154 -0.412929 -1.481050  0.328945 -0.733546 -0.116789  0.706199   \n",
       "5997   0.222099 -1.354657 -1.749921  0.102923  0.022114 -0.341273  0.246870   \n",
       "5998  -1.382804  1.352967 -1.648487 -0.993851  0.127188  0.234405 -0.267140   \n",
       "5999  -1.408683 -0.251507 -1.133444 -1.673723 -0.505760 -0.225619  0.297823   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "0    -1.000018 -0.262830 -0.126182  0.451391  0.250481 -0.449014  0.012944   \n",
       "1    -0.255812 -0.112504  0.236247 -0.035694 -0.094230  0.215514  0.197993   \n",
       "2    -0.802580 -0.616567 -0.089366 -0.140864 -0.115965  0.074073  0.106007   \n",
       "3    -0.084668 -0.423999  0.411282 -0.151000 -0.166272 -0.166718 -0.202987   \n",
       "4    -0.071524  0.226781 -0.177651  0.035830  0.298667  0.026282  0.189246   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5995 -0.175940  0.014415  0.236920  0.421853 -0.320831  0.331370  0.326219   \n",
       "5996  0.302345 -0.015092  0.088344  0.098513  0.324503 -0.244092 -0.442976   \n",
       "5997 -0.116025 -0.328617  0.411589  0.636721 -0.531026 -0.058351  0.822338   \n",
       "5998 -0.135703  0.000293 -0.145477 -0.054742 -0.352817 -0.083453  0.119906   \n",
       "5999  0.267031 -0.065843  0.216497  0.252764 -0.122092  0.153038 -0.273876   \n",
       "\n",
       "            14        15        16        17   18  \n",
       "0    -0.288916 -0.155867  0.107763  0.055629  1.0  \n",
       "1     0.107270 -0.276193  0.124229 -0.124303  1.0  \n",
       "2     0.095371 -0.213979  0.050795 -0.283725  1.0  \n",
       "3     0.350999  0.059044 -0.015877 -0.087901  1.0  \n",
       "4     0.466544 -0.371295  0.284428  0.048900  1.0  \n",
       "...        ...       ...       ...       ...  ...  \n",
       "5995 -0.410505 -0.408616 -0.274034 -0.193388  0.0  \n",
       "5996  0.105378  0.107065 -0.020756 -0.167451  0.0  \n",
       "5997  0.116245 -0.049143  0.209412  0.169790  0.0  \n",
       "5998 -0.220282  0.477581  0.332787  0.009730  0.0  \n",
       "5999 -0.439021  0.176175 -0.171015  0.477406  0.0  \n",
       "\n",
       "[6000 rows x 19 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X values\n",
      "[[ 1.30253200e+01 -1.14781184e+00  3.14124897e+00 ... -1.55866740e-01\n",
      "   1.07762930e-01  5.56291061e-02]\n",
      " [ 6.26627658e+00  7.57363931e-01  1.31019157e+00 ... -2.76192695e-01\n",
      "   1.24229211e-01 -1.24302894e-01]\n",
      " [ 1.15583348e+01 -2.03078801e+00  2.90010287e+00 ... -2.13978822e-01\n",
      "   5.07951056e-02 -2.83725270e-01]\n",
      " ...\n",
      " [ 2.22099084e-01 -1.35465740e+00 -1.74992052e+00 ... -4.91427849e-02\n",
      "   2.09412375e-01  1.69790062e-01]\n",
      " [-1.38280353e+00  1.35296677e+00 -1.64848723e+00 ...  4.77581114e-01\n",
      "   3.32787004e-01  9.72999184e-03]\n",
      " [-1.40868255e+00 -2.51507218e-01 -1.13344358e+00 ...  1.76174573e-01\n",
      "  -1.71014845e-01  4.77405786e-01]]\n",
      "Y values\n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "5995    0.0\n",
      "5996    0.0\n",
      "5997    0.0\n",
      "5998    0.0\n",
      "5999    0.0\n",
      "Name: 18, Length: 6000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#assigning x the columns from 1 to 18 for training\n",
    "x = train_data.iloc[:,0:18].values\n",
    "print(\"X values\")\n",
    "print(x)\n",
    "\n",
    "#assigning y with the column \"Class\" as target variable\n",
    "y = train_data.iloc[:,18]\n",
    "print(\"Y values\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset split into train and test with 80% Training and 20% Testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results\n",
      "Decision Tree Accuracy:  85.83333333333333 %\n",
      "Train Accuracy: 0.993125\n",
      "Test Accuracy: 0.8583333333333333\n",
      "Precision Score:  0.8583333333333333\n",
      "Recall Score:  0.8583333333333333\n",
      "F2 Score:  0.8583333333333333\n",
      "F1 Score:  0.8583333333333333\n",
      "Confusion Matrix: \n",
      "[[534  82]\n",
      " [ 88 496]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DedicatedSoftwares\\Anaconda3forme\\lib\\site-packages\\sklearn\\metrics\\classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#Assign model with Decision Tree classifier\n",
    "model_dt = DecisionTreeClassifier(max_depth=13)\n",
    "#training the model with the Training Variables \n",
    "model_dt.fit(x_train, y_train)\n",
    "#dumping the decision tree classifier model to the disk\n",
    "joblib.dump(model_dt,\"model_dt\")\n",
    "#predicting the target variable using testing variables\n",
    "y_pred1 = model_dt.predict(x_test)\n",
    "#Results\n",
    "print(\"Decision Tree Results\")\n",
    "print(\"Decision Tree Accuracy: \",accuracy_score(y_test, y_pred1)*100,\"%\")\n",
    "print(\"Train Accuracy:\",model_dt.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_dt.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred1, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred1, pos_label='positive', average='micro')) # true positive rate, Sensitivity\n",
    "print(\"F2 Score: \",metrics.fbeta_score(y_test, y_pred1, pos_label='positive', average='micro', beta=2.0))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred1, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Clasifier\n",
      "Train Accuracy: 0.9997916666666666\n",
      "Test Accuracy: 0.9016666666666666\n",
      "Precision Score:  0.9016666666666666\n",
      "Recall Score:  0.9016666666666666\n",
      "F1 Score:  0.9016666666666667\n",
      "Confusion Matrix: \n",
      "[[555  61]\n",
      " [ 57 527]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DedicatedSoftwares\\Anaconda3forme\\lib\\site-packages\\sklearn\\metrics\\classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#Random Forest classifier\n",
    "model_rf = RandomForestClassifier(n_estimators = 50)\n",
    "#training the model with train variables\n",
    "model_rf.fit(x_train, y_train)\n",
    "#dumping the random forest classifier model to the disk\n",
    "joblib.dump(model_rf,\"model_rf\")\n",
    "#predicting with the trained random forest model\n",
    "y_pred2 = model_rf.predict(x_test)\n",
    "print(\"Random Forest Clasifier\")\n",
    "print(\"Train Accuracy:\",model_rf.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_rf.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred2, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred2, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred2, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "Train Accuracy: 0.9435416666666666\n",
      "Test Accuracy: 0.9141666666666667\n",
      "Precision Score:  0.9141666666666667\n",
      "Recall Score:  0.9141666666666667\n",
      "F1 Score:  0.9141666666666667\n",
      "Confusion Matrix: \n",
      "[[562  54]\n",
      " [ 49 535]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DedicatedSoftwares\\Anaconda3forme\\lib\\site-packages\\sklearn\\metrics\\classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#KNN classifier\n",
    "model_knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "model_knn.fit(x_train, y_train)\n",
    "#dumping the KNN classifier model to the disk.\n",
    "joblib.dump(model_knn,\"model_knn\")\n",
    "y_pred3 = model_knn.predict(x_test)\n",
    "print(\"KNN\")\n",
    "print(\"Train Accuracy:\",model_knn.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_knn.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred3, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred3,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Linear kernel\n",
      "Train Accuracy: 0.893125\n",
      "Test Accuracy: 0.8975\n",
      "Precision Score:  0.8975\n",
      "Recall Score:  0.8975\n",
      "F1 Score:  0.8975\n",
      "Confusion Matrix: \n",
      "[[550  66]\n",
      " [ 57 527]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DedicatedSoftwares\\Anaconda3forme\\lib\\site-packages\\sklearn\\metrics\\classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#svm classifier\n",
    "model_svm = svm.SVC(kernel='linear') # Linear Kernel\n",
    "model_svm.fit(x_train, y_train)\n",
    "#dumping the svm classifier model to the disk\n",
    "joblib.dump(model_svm,\"model_svm\")\n",
    "#prediction\n",
    "y_pred4 = model_svm.predict(x_test)\n",
    "print(\"SVM Linear kernel\")\n",
    "print(\"Train Accuracy:\",model_svm.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_svm.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred4, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred4, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred4, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred4,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB\n",
      "Train Accuracy: 0.88625\n",
      "Test Accuracy: 0.9041666666666667\n",
      "Precision Score:  0.9041666666666667\n",
      "Recall Score:  0.9041666666666667\n",
      "F1 Score:  0.9041666666666667\n",
      "Confusion Matrix: \n",
      "[[570  46]\n",
      " [ 69 515]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DedicatedSoftwares\\Anaconda3forme\\lib\\site-packages\\sklearn\\metrics\\classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#gaussian naive bayes classifier\n",
    "model_nb = GaussianNB().fit(x_train, y_train)\n",
    "#dumping the naive bayes classifier model to the disk\n",
    "joblib.dump(model_nb,\"model_nb\")\n",
    "y_pred8 = model_nb.predict(x_test)\n",
    "print(\"Gaussian NB\")\n",
    "print(\"Train Accuracy:\",model_nb.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_nb.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred8, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred8, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred8, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred8,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGboost\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.9341666666666667\n",
      "Precision Score:  0.9341666666666667\n",
      "Recall Score:  0.9341666666666667\n",
      "F1 Score:  0.9341666666666667\n",
      "Confusion Matrix: \n",
      "[[575  41]\n",
      " [ 38 546]]\n"
     ]
    }
   ],
   "source": [
    "#xgboost classifier\n",
    "model_xgboost = XGBClassifier().fit(x_train, y_train)\n",
    "#dumping the xgboost classifier model to the disk.\n",
    "joblib.dump(model_nb,\"model_xgboost\")\n",
    "#prediction\n",
    "y_pred5 = model_xgboost.predict(x_test)\n",
    "print(\"XGboost\")\n",
    "print(\"Train Accuracy:\",model_xgboost.score(x_train, y_train))\n",
    "print(\"Test Accuracy:\",model_xgboost.score(x_test, y_test))\n",
    "print(\"Precision Score: \",metrics.precision_score(y_test, y_pred5, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y_test, y_pred5, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y_test, y_pred5, pos_label='positive', average='micro'))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred5,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with exclusive 1600 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lbp definiton for positve testing images\n",
    "def lbp_positive_testing(folder_name,radius, no_points ):\n",
    "    i=0\n",
    "    label=1\n",
    "    for filename in os.listdir(folder_name):\n",
    "        #path\n",
    "        path=os.path.join(folder_name,filename)\n",
    "        \n",
    "        #read the image\n",
    "        a=cv2.imread(path)\n",
    "        \n",
    "        #change the image from rgb to grayscale\n",
    "        a = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #apply gaussian filter\n",
    "        img_gaussian = cv2.GaussianBlur(a,(3,3),0)\n",
    "        \n",
    "        #define the kernel for prewitt edge detection operator\n",
    "        kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
    "        kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
    "        img_prewittx = cv2.filter2D(img_gaussian, -1, kernelx)\n",
    "        img_prewitty = cv2.filter2D(img_gaussian, -1, kernely)\n",
    "        prewitt = img_prewittx + img_prewitty\n",
    "        \n",
    "        #apply canny edge detection.\n",
    "        img_canny = cv2.Canny(a,100,200)\n",
    "        final_img = prewitt + img_canny\n",
    "        \n",
    "        #set radius for LBP\n",
    "        #radius = 3\n",
    "        \n",
    "        # Number of points to be considered as neighbourers \n",
    "        #no_points = 8 * radius\n",
    "        \n",
    "        # Uniform LBP is used\n",
    "        lbp = local_binary_pattern(final_img, no_points, radius, method='uniform')\n",
    "        \n",
    "        # Calculate the histogram\n",
    "        x = itemfreq(lbp.ravel())\n",
    "        \n",
    "        # Normalize the histogram\n",
    "        hist = x[:, 1]/sum(x[:, 1])\n",
    "        \n",
    "        hist.reshape(26,-1)\n",
    "        hist = np.append(hist, label)\n",
    "        #writing features to csv files\n",
    "        with open(r'testingcsv.csv', 'a',newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(hist)\n",
    "        i=i+1\n",
    "        if i==3000:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lbp definition for negative testing images\n",
    "def lbp_negative_testing(folder_name,radius, no_points ):\n",
    "    i=0\n",
    "    label=0\n",
    "    for filename in os.listdir(folder_name):\n",
    "        #path\n",
    "        path=os.path.join(folder_name,filename)\n",
    "        \n",
    "        #read the image\n",
    "        a=cv2.imread(path)\n",
    "        \n",
    "        #change the image from rgb to grayscale\n",
    "        a = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #apply gaussian filter\n",
    "        img_gaussian = cv2.GaussianBlur(a,(3,3),0)\n",
    "        \n",
    "        #define the kernel for prewitt edge detection operator\n",
    "        kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
    "        kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
    "        img_prewittx = cv2.filter2D(img_gaussian, -1, kernelx)\n",
    "        img_prewitty = cv2.filter2D(img_gaussian, -1, kernely)\n",
    "        prewitt = img_prewittx + img_prewitty\n",
    "        \n",
    "        #apply canny edge detection.\n",
    "        img_canny = cv2.Canny(a,100,200)\n",
    "        final_img = prewitt + img_canny\n",
    "        \n",
    "        #set radius for LBP\n",
    "        #radius = 3\n",
    "        \n",
    "        # Number of points to be considered as neighbourers \n",
    "        #no_points = 8 * radius\n",
    "        \n",
    "        # Uniform LBP is used\n",
    "        lbp = local_binary_pattern(final_img, no_points, radius, method='uniform')\n",
    "        \n",
    "        # Calculate the histogram\n",
    "        x = itemfreq(lbp.ravel())\n",
    "        \n",
    "        # Normalize the histogram\n",
    "        hist = x[:, 1]/sum(x[:, 1])\n",
    "        \n",
    "        hist.reshape(26,-1)\n",
    "        hist = np.append(hist, label)\n",
    "        #writing features to csv files\n",
    "        with open(r'testingcsv.csv', 'a',newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(hist)\n",
    "        i=i+1\n",
    "        if i==3000:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DedicatedSoftwares\\Anaconda3forme\\lib\\site-packages\\ipykernel_launcher.py:39: DeprecationWarning: `itemfreq` is deprecated!\n",
      "`itemfreq` is deprecated and will be removed in a future version. Use instead `np.unique(..., return_counts=True)`\n"
     ]
    }
   ],
   "source": [
    "#calling the lbp function for positive testing images\n",
    "lbp_positive_testing(r\"C:\\Users\\omkar\\OneDrive\\Desktop\\College work\\TY\\ML FINAL PROJECT\\testing_positive\",3,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DedicatedSoftwares\\Anaconda3forme\\lib\\site-packages\\ipykernel_launcher.py:39: DeprecationWarning: `itemfreq` is deprecated!\n",
      "`itemfreq` is deprecated and will be removed in a future version. Use instead `np.unique(..., return_counts=True)`\n"
     ]
    }
   ],
   "source": [
    "#calling the lbp function for negative testing images\n",
    "lbp_negative_testing(r\"C:\\Users\\omkar\\OneDrive\\Desktop\\College work\\TY\\ML FINAL PROJECT\\testing_negative\",3,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.061693</td>\n",
       "      <td>0.022939</td>\n",
       "      <td>0.032292</td>\n",
       "      <td>0.034117</td>\n",
       "      <td>0.027053</td>\n",
       "      <td>0.018184</td>\n",
       "      <td>0.013313</td>\n",
       "      <td>0.011954</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>0.013429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007239</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>0.007161</td>\n",
       "      <td>0.004522</td>\n",
       "      <td>0.272914</td>\n",
       "      <td>0.331988</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.066817</td>\n",
       "      <td>0.024084</td>\n",
       "      <td>0.033379</td>\n",
       "      <td>0.033360</td>\n",
       "      <td>0.025345</td>\n",
       "      <td>0.017815</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.010615</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.007491</td>\n",
       "      <td>0.007161</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>0.266277</td>\n",
       "      <td>0.374624</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.068330</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>0.030507</td>\n",
       "      <td>0.032001</td>\n",
       "      <td>0.026373</td>\n",
       "      <td>0.018417</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.010053</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>0.005706</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.304741</td>\n",
       "      <td>0.344602</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.069728</td>\n",
       "      <td>0.025403</td>\n",
       "      <td>0.032215</td>\n",
       "      <td>0.034932</td>\n",
       "      <td>0.025811</td>\n",
       "      <td>0.015254</td>\n",
       "      <td>0.011663</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.009839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006152</td>\n",
       "      <td>0.006152</td>\n",
       "      <td>0.006909</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>0.006831</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>0.301966</td>\n",
       "      <td>0.345786</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.067632</td>\n",
       "      <td>0.024355</td>\n",
       "      <td>0.031613</td>\n",
       "      <td>0.032098</td>\n",
       "      <td>0.024491</td>\n",
       "      <td>0.017291</td>\n",
       "      <td>0.012168</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.010674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>0.008422</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.286266</td>\n",
       "      <td>0.357604</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1595</td>\n",
       "      <td>0.064663</td>\n",
       "      <td>0.021658</td>\n",
       "      <td>0.031322</td>\n",
       "      <td>0.034738</td>\n",
       "      <td>0.029614</td>\n",
       "      <td>0.020881</td>\n",
       "      <td>0.014380</td>\n",
       "      <td>0.014516</td>\n",
       "      <td>0.012634</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>0.007433</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>0.006870</td>\n",
       "      <td>0.005123</td>\n",
       "      <td>0.277223</td>\n",
       "      <td>0.333812</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1596</td>\n",
       "      <td>0.082303</td>\n",
       "      <td>0.028683</td>\n",
       "      <td>0.035902</td>\n",
       "      <td>0.033864</td>\n",
       "      <td>0.020726</td>\n",
       "      <td>0.012634</td>\n",
       "      <td>0.007918</td>\n",
       "      <td>0.006870</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004502</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>0.005608</td>\n",
       "      <td>0.293621</td>\n",
       "      <td>0.387296</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1597</td>\n",
       "      <td>0.056182</td>\n",
       "      <td>0.019368</td>\n",
       "      <td>0.030061</td>\n",
       "      <td>0.033088</td>\n",
       "      <td>0.026703</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.014438</td>\n",
       "      <td>0.015370</td>\n",
       "      <td>0.017757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>0.009742</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>0.010557</td>\n",
       "      <td>0.009626</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.270547</td>\n",
       "      <td>0.294494</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1598</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.020532</td>\n",
       "      <td>0.030895</td>\n",
       "      <td>0.037125</td>\n",
       "      <td>0.029168</td>\n",
       "      <td>0.020319</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>0.012459</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>0.013410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008869</td>\n",
       "      <td>0.008578</td>\n",
       "      <td>0.008655</td>\n",
       "      <td>0.008131</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.288226</td>\n",
       "      <td>0.306041</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.022958</td>\n",
       "      <td>0.033748</td>\n",
       "      <td>0.035999</td>\n",
       "      <td>0.027130</td>\n",
       "      <td>0.018009</td>\n",
       "      <td>0.012207</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.010751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.008054</td>\n",
       "      <td>0.007860</td>\n",
       "      <td>0.007801</td>\n",
       "      <td>0.007491</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>0.266549</td>\n",
       "      <td>0.367191</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.061693  0.022939  0.032292  0.034117  0.027053  0.018184  0.013313   \n",
       "1     0.066817  0.024084  0.033379  0.033360  0.025345  0.017815  0.012226   \n",
       "2     0.068330  0.024161  0.030507  0.032001  0.026373  0.018417  0.012343   \n",
       "3     0.069728  0.025403  0.032215  0.034932  0.025811  0.015254  0.011663   \n",
       "4     0.067632  0.024355  0.031613  0.032098  0.024491  0.017291  0.012168   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1595  0.064663  0.021658  0.031322  0.034738  0.029614  0.020881  0.014380   \n",
       "1596  0.082303  0.028683  0.035902  0.033864  0.020726  0.012634  0.007918   \n",
       "1597  0.056182  0.019368  0.030061  0.033088  0.026703  0.020649  0.015292   \n",
       "1598  0.061538  0.020532  0.030895  0.037125  0.029168  0.020319  0.015448   \n",
       "1599  0.069514  0.022958  0.033748  0.035999  0.027130  0.018009  0.012207   \n",
       "\n",
       "            7         8         9   ...        17        18        19  \\\n",
       "0     0.011954  0.013119  0.013429  ...  0.007239  0.007083  0.008325   \n",
       "1     0.010615  0.010460  0.009781  ...  0.006462  0.005550  0.007200   \n",
       "2     0.009994  0.010053  0.010577  ...  0.005997  0.006307  0.007646   \n",
       "3     0.010091  0.009315  0.009839  ...  0.006152  0.006152  0.006909   \n",
       "4     0.010596  0.010538  0.010674  ...  0.007258  0.006889  0.008422   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1595  0.014516  0.012634  0.013546  ...  0.008151  0.007510  0.007433   \n",
       "1596  0.006870  0.006249  0.006482  ...  0.004502  0.003998  0.004561   \n",
       "1597  0.014438  0.015370  0.017757  ...  0.011372  0.009742  0.011081   \n",
       "1598  0.012459  0.012071  0.013410  ...  0.008869  0.008578  0.008655   \n",
       "1599  0.011333  0.010693  0.010751  ...  0.007258  0.006734  0.008054   \n",
       "\n",
       "            20        21        22        23        24        25   26  \n",
       "0     0.009238  0.008617  0.007161  0.004522  0.272914  0.331988  1.0  \n",
       "1     0.007491  0.007161  0.007607  0.005764  0.266277  0.374624  1.0  \n",
       "2     0.006540  0.005706  0.005162  0.003745  0.304741  0.344602  1.0  \n",
       "3     0.007510  0.006831  0.005531  0.004075  0.301966  0.345786  1.0  \n",
       "4     0.007258  0.007530  0.006307  0.005337  0.286266  0.357604  1.0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "1595  0.007898  0.006715  0.006870  0.005123  0.277223  0.333812  0.0  \n",
       "1596  0.007122  0.007588  0.007258  0.005608  0.293621  0.387296  0.0  \n",
       "1597  0.010557  0.009626  0.007646  0.005453  0.270547  0.294494  0.0  \n",
       "1598  0.008131  0.008617  0.005453  0.003959  0.288226  0.306041  0.0  \n",
       "1599  0.007860  0.007801  0.007491  0.005007  0.266549  0.367191  0.0  \n",
       "\n",
       "[1600 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the csv file.\n",
    "data= pd.read_csv('C:\\\\Users\\\\omkar\\\\OneDrive\\\\Desktop\\\\College work\\\\TY\\\\ML FINAL PROJECT\\\\testingcsv.csv',header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into \n",
    "x = data.iloc[:,0:26].values\n",
    "y = data.iloc[:,26].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the testing data with standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_obj = StandardScaler()\n",
    "scalardata = std_obj.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.87281928,  0.32836133,  0.2551524 , ..., -0.01354229,\n",
       "        -0.68606689,  0.1097835 ],\n",
       "       [ 0.09991481,  0.83780845,  0.7226518 , ...,  1.11663763,\n",
       "        -0.97310442,  1.58480353],\n",
       "       [ 0.38731351,  0.87234724, -0.51288232, ..., -0.71990475,\n",
       "         0.69037036,  0.54617996],\n",
       "       ...,\n",
       "       [-1.91924534, -1.2604229 , -0.704891  , ...,  0.83409265,\n",
       "        -0.78846039, -1.18732105],\n",
       "       [-0.90229607, -0.74234108, -0.34591825, ..., -0.52565507,\n",
       "        -0.02386629, -0.78785045],\n",
       "       [ 0.61207404,  0.33699603,  0.88126767, ...,  0.42793424,\n",
       "        -0.96135434,  1.32766531]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalardata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the already trained PCA model.\n",
    "pca = pickle.load(open('C:\\\\Users\\\\omkar\\\\OneDrive\\\\Desktop\\\\College work\\\\TY\\\\ML FINAL PROJECT\\\\PCA_Model.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the testing data with 18 columns\n",
    "new_scalardata = pca.transform(scalardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3608204 ,  0.76463133,  0.39013855, ..., -0.16289829,\n",
       "        -0.19090485, -0.19270764],\n",
       "       [ 3.00892559,  1.43514039,  0.01685336, ..., -0.31711906,\n",
       "         0.07148968, -0.13345234],\n",
       "       [ 3.08309845, -1.7423547 ,  0.08320101, ..., -0.35545487,\n",
       "        -0.08623512, -0.34017242],\n",
       "       ...,\n",
       "       [-7.24790402,  1.94917079,  1.15591419, ..., -0.03276779,\n",
       "         0.575312  , -0.20130642],\n",
       "       [-3.27921173, -0.784945  , -1.21794194, ..., -0.05829294,\n",
       "        -0.13852957,  0.04687211],\n",
       "       [ 2.34452407,  1.65501368, -1.7123903 , ..., -0.23235169,\n",
       "        -0.04403905,  0.02220744]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scalardata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scalardata = pd.DataFrame(new_scalardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.360820</td>\n",
       "      <td>0.764631</td>\n",
       "      <td>0.390139</td>\n",
       "      <td>0.533078</td>\n",
       "      <td>-0.063846</td>\n",
       "      <td>0.815354</td>\n",
       "      <td>-0.755753</td>\n",
       "      <td>-0.074695</td>\n",
       "      <td>-0.789802</td>\n",
       "      <td>-0.476626</td>\n",
       "      <td>-0.357939</td>\n",
       "      <td>0.219017</td>\n",
       "      <td>-0.185414</td>\n",
       "      <td>0.586632</td>\n",
       "      <td>-0.227226</td>\n",
       "      <td>-0.162898</td>\n",
       "      <td>-0.190905</td>\n",
       "      <td>-0.192708</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.008926</td>\n",
       "      <td>1.435140</td>\n",
       "      <td>0.016853</td>\n",
       "      <td>-0.502297</td>\n",
       "      <td>1.227377</td>\n",
       "      <td>0.919127</td>\n",
       "      <td>0.124087</td>\n",
       "      <td>-0.888523</td>\n",
       "      <td>-0.219487</td>\n",
       "      <td>-0.629717</td>\n",
       "      <td>0.080140</td>\n",
       "      <td>0.146871</td>\n",
       "      <td>0.171150</td>\n",
       "      <td>0.473365</td>\n",
       "      <td>0.563691</td>\n",
       "      <td>-0.317119</td>\n",
       "      <td>0.071490</td>\n",
       "      <td>-0.133452</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.083098</td>\n",
       "      <td>-1.742355</td>\n",
       "      <td>0.083201</td>\n",
       "      <td>-1.777882</td>\n",
       "      <td>0.346577</td>\n",
       "      <td>-0.492225</td>\n",
       "      <td>0.344807</td>\n",
       "      <td>0.027006</td>\n",
       "      <td>-0.276726</td>\n",
       "      <td>-0.804279</td>\n",
       "      <td>0.572477</td>\n",
       "      <td>-0.483337</td>\n",
       "      <td>0.269811</td>\n",
       "      <td>0.028595</td>\n",
       "      <td>0.241710</td>\n",
       "      <td>-0.355455</td>\n",
       "      <td>-0.086235</td>\n",
       "      <td>-0.340172</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.879804</td>\n",
       "      <td>-0.760606</td>\n",
       "      <td>-0.459081</td>\n",
       "      <td>-0.216910</td>\n",
       "      <td>0.027360</td>\n",
       "      <td>-0.202904</td>\n",
       "      <td>0.403361</td>\n",
       "      <td>0.367467</td>\n",
       "      <td>-0.802595</td>\n",
       "      <td>-0.260181</td>\n",
       "      <td>-0.205700</td>\n",
       "      <td>0.046845</td>\n",
       "      <td>0.050155</td>\n",
       "      <td>-0.090197</td>\n",
       "      <td>0.106812</td>\n",
       "      <td>0.228399</td>\n",
       "      <td>-0.084281</td>\n",
       "      <td>0.283524</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.679669</td>\n",
       "      <td>0.932757</td>\n",
       "      <td>0.348940</td>\n",
       "      <td>-1.550542</td>\n",
       "      <td>0.179425</td>\n",
       "      <td>0.301049</td>\n",
       "      <td>0.272849</td>\n",
       "      <td>0.127642</td>\n",
       "      <td>-0.239756</td>\n",
       "      <td>-0.130384</td>\n",
       "      <td>0.159657</td>\n",
       "      <td>-0.696802</td>\n",
       "      <td>0.014130</td>\n",
       "      <td>0.057531</td>\n",
       "      <td>0.260236</td>\n",
       "      <td>0.005547</td>\n",
       "      <td>0.303736</td>\n",
       "      <td>-0.190984</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1595</td>\n",
       "      <td>-1.181812</td>\n",
       "      <td>-0.050284</td>\n",
       "      <td>-1.282469</td>\n",
       "      <td>-1.355179</td>\n",
       "      <td>1.384810</td>\n",
       "      <td>0.659021</td>\n",
       "      <td>-0.242646</td>\n",
       "      <td>-0.785397</td>\n",
       "      <td>-0.346143</td>\n",
       "      <td>-0.600351</td>\n",
       "      <td>-0.007443</td>\n",
       "      <td>0.277206</td>\n",
       "      <td>0.637114</td>\n",
       "      <td>-0.222885</td>\n",
       "      <td>-0.065938</td>\n",
       "      <td>0.392196</td>\n",
       "      <td>0.047670</td>\n",
       "      <td>0.320624</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1596</td>\n",
       "      <td>10.161428</td>\n",
       "      <td>1.670578</td>\n",
       "      <td>0.297510</td>\n",
       "      <td>0.722486</td>\n",
       "      <td>0.411563</td>\n",
       "      <td>-0.302222</td>\n",
       "      <td>-0.064135</td>\n",
       "      <td>-0.382794</td>\n",
       "      <td>-0.505086</td>\n",
       "      <td>0.437901</td>\n",
       "      <td>-0.369121</td>\n",
       "      <td>0.767236</td>\n",
       "      <td>0.432063</td>\n",
       "      <td>-0.282709</td>\n",
       "      <td>0.325316</td>\n",
       "      <td>0.329139</td>\n",
       "      <td>0.530789</td>\n",
       "      <td>-0.136678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1597</td>\n",
       "      <td>-7.247904</td>\n",
       "      <td>1.949171</td>\n",
       "      <td>1.155914</td>\n",
       "      <td>-0.294698</td>\n",
       "      <td>-1.104170</td>\n",
       "      <td>1.000562</td>\n",
       "      <td>-0.397174</td>\n",
       "      <td>0.423494</td>\n",
       "      <td>0.133818</td>\n",
       "      <td>0.314010</td>\n",
       "      <td>-0.809216</td>\n",
       "      <td>-0.155703</td>\n",
       "      <td>0.078893</td>\n",
       "      <td>0.409458</td>\n",
       "      <td>-0.147360</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>0.575312</td>\n",
       "      <td>-0.201306</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1598</td>\n",
       "      <td>-3.279212</td>\n",
       "      <td>-0.784945</td>\n",
       "      <td>-1.217942</td>\n",
       "      <td>0.350647</td>\n",
       "      <td>-0.245601</td>\n",
       "      <td>0.094625</td>\n",
       "      <td>0.091969</td>\n",
       "      <td>0.146347</td>\n",
       "      <td>-0.489171</td>\n",
       "      <td>0.646635</td>\n",
       "      <td>0.038247</td>\n",
       "      <td>-0.201336</td>\n",
       "      <td>-0.718752</td>\n",
       "      <td>-0.377942</td>\n",
       "      <td>0.769535</td>\n",
       "      <td>-0.058293</td>\n",
       "      <td>-0.138530</td>\n",
       "      <td>0.046872</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599</td>\n",
       "      <td>2.344524</td>\n",
       "      <td>1.655014</td>\n",
       "      <td>-1.712390</td>\n",
       "      <td>-0.164453</td>\n",
       "      <td>0.756898</td>\n",
       "      <td>0.344428</td>\n",
       "      <td>0.011542</td>\n",
       "      <td>-0.536939</td>\n",
       "      <td>-0.252446</td>\n",
       "      <td>-0.129789</td>\n",
       "      <td>0.008512</td>\n",
       "      <td>-0.259502</td>\n",
       "      <td>0.252704</td>\n",
       "      <td>0.213077</td>\n",
       "      <td>-0.032706</td>\n",
       "      <td>-0.232352</td>\n",
       "      <td>-0.044039</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0     -1.360820  0.764631  0.390139  0.533078 -0.063846  0.815354 -0.755753   \n",
       "1      3.008926  1.435140  0.016853 -0.502297  1.227377  0.919127  0.124087   \n",
       "2      3.083098 -1.742355  0.083201 -1.777882  0.346577 -0.492225  0.344807   \n",
       "3      3.879804 -0.760606 -0.459081 -0.216910  0.027360 -0.202904  0.403361   \n",
       "4      2.679669  0.932757  0.348940 -1.550542  0.179425  0.301049  0.272849   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "1595  -1.181812 -0.050284 -1.282469 -1.355179  1.384810  0.659021 -0.242646   \n",
       "1596  10.161428  1.670578  0.297510  0.722486  0.411563 -0.302222 -0.064135   \n",
       "1597  -7.247904  1.949171  1.155914 -0.294698 -1.104170  1.000562 -0.397174   \n",
       "1598  -3.279212 -0.784945 -1.217942  0.350647 -0.245601  0.094625  0.091969   \n",
       "1599   2.344524  1.655014 -1.712390 -0.164453  0.756898  0.344428  0.011542   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "0    -0.074695 -0.789802 -0.476626 -0.357939  0.219017 -0.185414  0.586632   \n",
       "1    -0.888523 -0.219487 -0.629717  0.080140  0.146871  0.171150  0.473365   \n",
       "2     0.027006 -0.276726 -0.804279  0.572477 -0.483337  0.269811  0.028595   \n",
       "3     0.367467 -0.802595 -0.260181 -0.205700  0.046845  0.050155 -0.090197   \n",
       "4     0.127642 -0.239756 -0.130384  0.159657 -0.696802  0.014130  0.057531   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1595 -0.785397 -0.346143 -0.600351 -0.007443  0.277206  0.637114 -0.222885   \n",
       "1596 -0.382794 -0.505086  0.437901 -0.369121  0.767236  0.432063 -0.282709   \n",
       "1597  0.423494  0.133818  0.314010 -0.809216 -0.155703  0.078893  0.409458   \n",
       "1598  0.146347 -0.489171  0.646635  0.038247 -0.201336 -0.718752 -0.377942   \n",
       "1599 -0.536939 -0.252446 -0.129789  0.008512 -0.259502  0.252704  0.213077   \n",
       "\n",
       "            14        15        16        17   0   \n",
       "0    -0.227226 -0.162898 -0.190905 -0.192708  1.0  \n",
       "1     0.563691 -0.317119  0.071490 -0.133452  1.0  \n",
       "2     0.241710 -0.355455 -0.086235 -0.340172  1.0  \n",
       "3     0.106812  0.228399 -0.084281  0.283524  1.0  \n",
       "4     0.260236  0.005547  0.303736 -0.190984  1.0  \n",
       "...        ...       ...       ...       ...  ...  \n",
       "1595 -0.065938  0.392196  0.047670  0.320624  0.0  \n",
       "1596  0.325316  0.329139  0.530789 -0.136678  0.0  \n",
       "1597 -0.147360 -0.032768  0.575312 -0.201306  0.0  \n",
       "1598  0.769535 -0.058293 -0.138530  0.046872  0.0  \n",
       "1599 -0.032706 -0.232352 -0.044039  0.022207  0.0  \n",
       "\n",
       "[1600 rows x 19 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#appending the label to the final testing data.\n",
    "testing_label_column = pd.concat([new_scalardata, pd.DataFrame(y)],axis=1)\n",
    "testing_label_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the datafile into csv format.\n",
    "csv_data_t1=testing_label_column.to_csv('C:\\\\Users\\\\omkar\\\\OneDrive\\\\Desktop\\\\College work\\\\TY\\\\ML FINAL PROJECT\\\\testing_FinalPCAFV.csv', mode='a',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.360820</td>\n",
       "      <td>0.764631</td>\n",
       "      <td>0.390139</td>\n",
       "      <td>0.533078</td>\n",
       "      <td>-0.063846</td>\n",
       "      <td>0.815354</td>\n",
       "      <td>-0.755753</td>\n",
       "      <td>-0.074695</td>\n",
       "      <td>-0.789802</td>\n",
       "      <td>-0.476626</td>\n",
       "      <td>-0.357939</td>\n",
       "      <td>0.219017</td>\n",
       "      <td>-0.185414</td>\n",
       "      <td>0.586632</td>\n",
       "      <td>-0.227226</td>\n",
       "      <td>-0.162898</td>\n",
       "      <td>-0.190905</td>\n",
       "      <td>-0.192708</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.008926</td>\n",
       "      <td>1.435140</td>\n",
       "      <td>0.016853</td>\n",
       "      <td>-0.502297</td>\n",
       "      <td>1.227377</td>\n",
       "      <td>0.919127</td>\n",
       "      <td>0.124087</td>\n",
       "      <td>-0.888523</td>\n",
       "      <td>-0.219487</td>\n",
       "      <td>-0.629717</td>\n",
       "      <td>0.080140</td>\n",
       "      <td>0.146871</td>\n",
       "      <td>0.171150</td>\n",
       "      <td>0.473365</td>\n",
       "      <td>0.563691</td>\n",
       "      <td>-0.317119</td>\n",
       "      <td>0.071490</td>\n",
       "      <td>-0.133452</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.083098</td>\n",
       "      <td>-1.742355</td>\n",
       "      <td>0.083201</td>\n",
       "      <td>-1.777882</td>\n",
       "      <td>0.346577</td>\n",
       "      <td>-0.492225</td>\n",
       "      <td>0.344807</td>\n",
       "      <td>0.027006</td>\n",
       "      <td>-0.276726</td>\n",
       "      <td>-0.804279</td>\n",
       "      <td>0.572477</td>\n",
       "      <td>-0.483337</td>\n",
       "      <td>0.269811</td>\n",
       "      <td>0.028595</td>\n",
       "      <td>0.241710</td>\n",
       "      <td>-0.355455</td>\n",
       "      <td>-0.086235</td>\n",
       "      <td>-0.340172</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.879804</td>\n",
       "      <td>-0.760606</td>\n",
       "      <td>-0.459081</td>\n",
       "      <td>-0.216910</td>\n",
       "      <td>0.027360</td>\n",
       "      <td>-0.202904</td>\n",
       "      <td>0.403361</td>\n",
       "      <td>0.367467</td>\n",
       "      <td>-0.802595</td>\n",
       "      <td>-0.260181</td>\n",
       "      <td>-0.205700</td>\n",
       "      <td>0.046845</td>\n",
       "      <td>0.050155</td>\n",
       "      <td>-0.090197</td>\n",
       "      <td>0.106812</td>\n",
       "      <td>0.228399</td>\n",
       "      <td>-0.084281</td>\n",
       "      <td>0.283524</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.679669</td>\n",
       "      <td>0.932757</td>\n",
       "      <td>0.348940</td>\n",
       "      <td>-1.550542</td>\n",
       "      <td>0.179425</td>\n",
       "      <td>0.301049</td>\n",
       "      <td>0.272849</td>\n",
       "      <td>0.127642</td>\n",
       "      <td>-0.239756</td>\n",
       "      <td>-0.130384</td>\n",
       "      <td>0.159657</td>\n",
       "      <td>-0.696802</td>\n",
       "      <td>0.014130</td>\n",
       "      <td>0.057531</td>\n",
       "      <td>0.260236</td>\n",
       "      <td>0.005547</td>\n",
       "      <td>0.303736</td>\n",
       "      <td>-0.190984</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1595</td>\n",
       "      <td>-1.181812</td>\n",
       "      <td>-0.050284</td>\n",
       "      <td>-1.282469</td>\n",
       "      <td>-1.355179</td>\n",
       "      <td>1.384810</td>\n",
       "      <td>0.659021</td>\n",
       "      <td>-0.242646</td>\n",
       "      <td>-0.785397</td>\n",
       "      <td>-0.346143</td>\n",
       "      <td>-0.600351</td>\n",
       "      <td>-0.007443</td>\n",
       "      <td>0.277206</td>\n",
       "      <td>0.637114</td>\n",
       "      <td>-0.222885</td>\n",
       "      <td>-0.065938</td>\n",
       "      <td>0.392196</td>\n",
       "      <td>0.047670</td>\n",
       "      <td>0.320624</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1596</td>\n",
       "      <td>10.161428</td>\n",
       "      <td>1.670578</td>\n",
       "      <td>0.297510</td>\n",
       "      <td>0.722486</td>\n",
       "      <td>0.411563</td>\n",
       "      <td>-0.302222</td>\n",
       "      <td>-0.064135</td>\n",
       "      <td>-0.382794</td>\n",
       "      <td>-0.505086</td>\n",
       "      <td>0.437901</td>\n",
       "      <td>-0.369121</td>\n",
       "      <td>0.767236</td>\n",
       "      <td>0.432063</td>\n",
       "      <td>-0.282709</td>\n",
       "      <td>0.325316</td>\n",
       "      <td>0.329139</td>\n",
       "      <td>0.530789</td>\n",
       "      <td>-0.136678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1597</td>\n",
       "      <td>-7.247904</td>\n",
       "      <td>1.949171</td>\n",
       "      <td>1.155914</td>\n",
       "      <td>-0.294698</td>\n",
       "      <td>-1.104170</td>\n",
       "      <td>1.000562</td>\n",
       "      <td>-0.397174</td>\n",
       "      <td>0.423494</td>\n",
       "      <td>0.133818</td>\n",
       "      <td>0.314010</td>\n",
       "      <td>-0.809216</td>\n",
       "      <td>-0.155703</td>\n",
       "      <td>0.078893</td>\n",
       "      <td>0.409458</td>\n",
       "      <td>-0.147360</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>0.575312</td>\n",
       "      <td>-0.201306</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1598</td>\n",
       "      <td>-3.279212</td>\n",
       "      <td>-0.784945</td>\n",
       "      <td>-1.217942</td>\n",
       "      <td>0.350647</td>\n",
       "      <td>-0.245601</td>\n",
       "      <td>0.094625</td>\n",
       "      <td>0.091969</td>\n",
       "      <td>0.146347</td>\n",
       "      <td>-0.489171</td>\n",
       "      <td>0.646635</td>\n",
       "      <td>0.038247</td>\n",
       "      <td>-0.201336</td>\n",
       "      <td>-0.718752</td>\n",
       "      <td>-0.377942</td>\n",
       "      <td>0.769535</td>\n",
       "      <td>-0.058293</td>\n",
       "      <td>-0.138530</td>\n",
       "      <td>0.046872</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599</td>\n",
       "      <td>2.344524</td>\n",
       "      <td>1.655014</td>\n",
       "      <td>-1.712390</td>\n",
       "      <td>-0.164453</td>\n",
       "      <td>0.756898</td>\n",
       "      <td>0.344428</td>\n",
       "      <td>0.011542</td>\n",
       "      <td>-0.536939</td>\n",
       "      <td>-0.252446</td>\n",
       "      <td>-0.129789</td>\n",
       "      <td>0.008512</td>\n",
       "      <td>-0.259502</td>\n",
       "      <td>0.252704</td>\n",
       "      <td>0.213077</td>\n",
       "      <td>-0.032706</td>\n",
       "      <td>-0.232352</td>\n",
       "      <td>-0.044039</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0     -1.360820  0.764631  0.390139  0.533078 -0.063846  0.815354 -0.755753   \n",
       "1      3.008926  1.435140  0.016853 -0.502297  1.227377  0.919127  0.124087   \n",
       "2      3.083098 -1.742355  0.083201 -1.777882  0.346577 -0.492225  0.344807   \n",
       "3      3.879804 -0.760606 -0.459081 -0.216910  0.027360 -0.202904  0.403361   \n",
       "4      2.679669  0.932757  0.348940 -1.550542  0.179425  0.301049  0.272849   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "1595  -1.181812 -0.050284 -1.282469 -1.355179  1.384810  0.659021 -0.242646   \n",
       "1596  10.161428  1.670578  0.297510  0.722486  0.411563 -0.302222 -0.064135   \n",
       "1597  -7.247904  1.949171  1.155914 -0.294698 -1.104170  1.000562 -0.397174   \n",
       "1598  -3.279212 -0.784945 -1.217942  0.350647 -0.245601  0.094625  0.091969   \n",
       "1599   2.344524  1.655014 -1.712390 -0.164453  0.756898  0.344428  0.011542   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "0    -0.074695 -0.789802 -0.476626 -0.357939  0.219017 -0.185414  0.586632   \n",
       "1    -0.888523 -0.219487 -0.629717  0.080140  0.146871  0.171150  0.473365   \n",
       "2     0.027006 -0.276726 -0.804279  0.572477 -0.483337  0.269811  0.028595   \n",
       "3     0.367467 -0.802595 -0.260181 -0.205700  0.046845  0.050155 -0.090197   \n",
       "4     0.127642 -0.239756 -0.130384  0.159657 -0.696802  0.014130  0.057531   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1595 -0.785397 -0.346143 -0.600351 -0.007443  0.277206  0.637114 -0.222885   \n",
       "1596 -0.382794 -0.505086  0.437901 -0.369121  0.767236  0.432063 -0.282709   \n",
       "1597  0.423494  0.133818  0.314010 -0.809216 -0.155703  0.078893  0.409458   \n",
       "1598  0.146347 -0.489171  0.646635  0.038247 -0.201336 -0.718752 -0.377942   \n",
       "1599 -0.536939 -0.252446 -0.129789  0.008512 -0.259502  0.252704  0.213077   \n",
       "\n",
       "            14        15        16        17   18  \n",
       "0    -0.227226 -0.162898 -0.190905 -0.192708  1.0  \n",
       "1     0.563691 -0.317119  0.071490 -0.133452  1.0  \n",
       "2     0.241710 -0.355455 -0.086235 -0.340172  1.0  \n",
       "3     0.106812  0.228399 -0.084281  0.283524  1.0  \n",
       "4     0.260236  0.005547  0.303736 -0.190984  1.0  \n",
       "...        ...       ...       ...       ...  ...  \n",
       "1595 -0.065938  0.392196  0.047670  0.320624  0.0  \n",
       "1596  0.325316  0.329139  0.530789 -0.136678  0.0  \n",
       "1597 -0.147360 -0.032768  0.575312 -0.201306  0.0  \n",
       "1598  0.769535 -0.058293 -0.138530  0.046872  0.0  \n",
       "1599 -0.032706 -0.232352 -0.044039  0.022207  0.0  \n",
       "\n",
       "[1600 rows x 19 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the csv file.\n",
    "data2= pd.read_csv(r'C:\\\\Users\\\\omkar\\\\OneDrive\\\\Desktop\\\\College work\\\\TY\\\\ML FINAL PROJECT\\\\testing_FinalPCAFV.csv',header=None)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X values\n",
      "[[-1.3608204   0.76463133  0.39013855 ... -0.16289829 -0.19090485\n",
      "  -0.19270764]\n",
      " [ 3.00892559  1.43514039  0.01685336 ... -0.31711906  0.07148968\n",
      "  -0.13345234]\n",
      " [ 3.08309845 -1.7423547   0.08320101 ... -0.35545487 -0.08623512\n",
      "  -0.34017242]\n",
      " ...\n",
      " [-7.24790402  1.94917079  1.15591419 ... -0.03276779  0.575312\n",
      "  -0.20130642]\n",
      " [-3.27921173 -0.784945   -1.21794194 ... -0.05829294 -0.13852957\n",
      "   0.04687211]\n",
      " [ 2.34452407  1.65501368 -1.7123903  ... -0.23235169 -0.04403905\n",
      "   0.02220744]]\n",
      "Y values\n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "1595    0.0\n",
      "1596    0.0\n",
      "1597    0.0\n",
      "1598    0.0\n",
      "1599    0.0\n",
      "Name: 18, Length: 1600, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#assigning x the columns from 1 to 18 for training\n",
    "x1 = data2.iloc[:,0:18].values\n",
    "print(\"X values\")\n",
    "print(x1)\n",
    "\n",
    "#assigning y with the column \"Class\" as target variable\n",
    "y1 = data2.iloc[:,18]\n",
    "print(\"Y values\")\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results\n",
      "Decision Tree Accuracy:  83.5625 %\n"
     ]
    }
   ],
   "source": [
    "#loading the decision tree classifier.\n",
    "model_dt = joblib.load(\"C:\\\\Users\\\\omkar\\\\OneDrive\\\\Desktop\\\\College work\\\\TY\\\\ML FINAL PROJECT\\\\model_dt\")\n",
    "#prediction\n",
    "y_dt = model_dt.predict(x1)\n",
    "print(\"Decision Tree Results\")\n",
    "print(\"Decision Tree Accuracy: \",accuracy_score(y1, y_dt)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Clasifier\n",
      "Random Forest Clasifier:  89.5625 %\n",
      "Precision Score:  0.895625\n",
      "Recall Score:  0.895625\n",
      "F1 Score:  0.895625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DedicatedSoftwares\\Anaconda3forme\\lib\\site-packages\\sklearn\\metrics\\classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#loading the Random forest classifier.\n",
    "model_rf = joblib.load(\"C:\\\\Users\\\\omkar\\\\OneDrive\\\\Desktop\\\\College work\\\\TY\\\\ML FINAL PROJECT\\\\model_rf\")\n",
    "#prediction\n",
    "y_rf = model_rf.predict(x1)\n",
    "print(\"Random Forest Clasifier\")\n",
    "print(\"Random Forest Clasifier: \",accuracy_score(y1, y_rf)*100,\"%\")\n",
    "print(\"Precision Score: \",metrics.precision_score(y1, y_rf, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y1, y_rf, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y1, y_rf, pos_label='positive', average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "KNN:  88.6875 %\n",
      "Precision Score:  0.886875\n",
      "Recall Score:  0.886875\n",
      "F1 Score:  0.886875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DedicatedSoftwares\\Anaconda3forme\\lib\\site-packages\\sklearn\\metrics\\classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#loading the KNN classifier.\n",
    "model_knn = joblib.load(\"C:\\\\Users\\\\omkar\\\\OneDrive\\\\Desktop\\\\College work\\\\TY\\\\ML FINAL PROJECT\\\\model_knn\")\n",
    "#prediction\n",
    "y_knn = model_knn.predict(x1)\n",
    "print(\"KNN\")\n",
    "print(\"KNN: \",accuracy_score(y1, y_knn)*100,\"%\")\n",
    "print(\"Precision Score: \",metrics.precision_score(y1, y_knn, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y1, y_knn, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y1, y_knn, pos_label='positive', average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "SVM:  88.8125 %\n",
      "Precision Score:  0.888125\n",
      "Recall Score:  0.888125\n",
      "F1 Score:  0.8881250000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DedicatedSoftwares\\Anaconda3forme\\lib\\site-packages\\sklearn\\metrics\\classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#loading the svm classifier.\n",
    "model_svm = joblib.load(\"C:\\\\Users\\\\omkar\\\\OneDrive\\\\Desktop\\\\College work\\\\TY\\\\ML FINAL PROJECT\\\\model_svm\")\n",
    "#prediction\n",
    "y_svm = model_svm.predict(x1)\n",
    "print(\"SVM\")\n",
    "print(\"SVM: \",accuracy_score(y1, y_svm)*100,\"%\")\n",
    "print(\"Precision Score: \",metrics.precision_score(y1, y_svm, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y1, y_svm, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y1, y_svm, pos_label='positive', average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guassian NB\n",
      "Guassian NB:  88.625 %\n",
      "Precision Score:  0.88625\n",
      "Recall Score:  0.88625\n",
      "F1 Score:  0.88625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DedicatedSoftwares\\Anaconda3forme\\lib\\site-packages\\sklearn\\metrics\\classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#loading the gaussian naive bayes classifier.\n",
    "model_nb = joblib.load(\"C:\\\\Users\\\\omkar\\\\OneDrive\\\\Desktop\\\\College work\\\\TY\\\\ML FINAL PROJECT\\\\model_nb\")\n",
    "#prediction\n",
    "y_nb = model_nb.predict(x1)\n",
    "print(\"Guassian NB\")\n",
    "print(\"Guassian NB: \",accuracy_score(y1, y_nb)*100,\"%\")\n",
    "print(\"Precision Score: \",metrics.precision_score(y1, y_nb, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y1, y_nb, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y1, y_nb, pos_label='positive', average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGboost\n",
      "XGboost:  88.625 %\n",
      "Precision Score:  0.88625\n",
      "Recall Score:  0.88625\n",
      "F1 Score:  0.88625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DedicatedSoftwares\\Anaconda3forme\\lib\\site-packages\\sklearn\\metrics\\classification.py:1259: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'micro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#loading the xgboost tree classifier.\n",
    "model_xgboost = joblib.load(\"C:\\\\Users\\\\omkar\\\\OneDrive\\\\Desktop\\\\College work\\\\TY\\\\ML FINAL PROJECT\\\\model_xgboost\")\n",
    "#prediction\n",
    "y_xgboost = model_xgboost.predict(x1)\n",
    "print(\"XGboost\")\n",
    "print(\"XGboost: \",accuracy_score(y1, y_nb)*100,\"%\")\n",
    "print(\"Precision Score: \",metrics.precision_score(y1, y_xgboost, pos_label='positive', average='micro'))\n",
    "print(\"Recall Score: \",metrics.recall_score(y1, y_xgboost, pos_label='positive', average='micro'))\n",
    "print(\"F1 Score: \",metrics.f1_score(y1, y_xgboost, pos_label='positive', average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2def7e6b64ac76d5a1871991a471fc3f43651d1da2d2d8ab819497a52e3540e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
